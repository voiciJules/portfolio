{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70b70ce3-ddae-4e1f-9112-d26f87052590",
   "metadata": {},
   "source": [
    "# Lesson 3\n",
    "\n",
    "### Convolutional layer\n",
    "합성곱 층은 합성곱 신경망(CNN)의 핵심 구성 요소로, 주로 이미지 데이터를 처리하는 데 사용됩니다. 합성곱 층의 주요 목적은 입력 데이터에서 국소적인 패턴을 찾는 것입니다. 이 작업은 합성곱 필터(또는 커널)를 통해 이루어집니다.\n",
    "  \n",
    "#### 입력 텐서  \n",
    "입력 데이터는 4D 텐서로 주어집니다. 형태는 (N, H, W, C)와 같습니다:    \n",
    "- N: 이미지의 개수 (배치 크기)  \n",
    "- H: 이미지의 높이  \n",
    "- W: 이미지의 너비  \n",
    "- C: 색상 채널의 수 (예: RGB 이미지라면 C=3)  \n",
    "\n",
    "#### 합성곱 층의 동작\n",
    "##### 필터(커널)\n",
    "- 합성곱 층은 학습 가능한 필터(또는 커널)를 사용하여 이미지에서 패턴을 찾아냅니다. 각 필터는 일반적으로 (F_h, F_w, C) 크기를 가지며, 여기서:\n",
    "  - F_h: 필터의 높이\n",
    "  - F_w: 필터의 너비\n",
    "  - C: 입력 채널의 수 (입력 이미지와 동일)\n",
    "##### 합성곱 연산:\n",
    "- 필터는 이미지 위를 슬라이딩(이동)하면서, 현재 위치한 이미지의 작은 영역과 내적을 계산합니다. 이렇게 얻어진 값은 출력 특징 맵에 기록됩니다. 이 작업은 이미지를 전부 스캔하면서 반복되며, 그 결과 특징 맵이 생성됩니다. 특징 맵은 이미지에서 모서리, 텍스처 등 다양한 패턴을 나타냅니다.\n",
    "##### 스트라이드(Stride):\n",
    "- 스트라이드는 필터가 이미지 위에서 이동하는 간격을 의미합니다. 예를 들어, 스트라이드 1은 필터가 한 픽셀씩 이동하는 방식이고, 스트라이드 2는 두 픽셀씩 이동하는 방식입니다.\n",
    "##### 패딩(Padding):\n",
    "- 패딩은 출력 크기를 제어하기 위해 사용됩니다. Valid 패딩(패딩 없음)을 사용하면 출력 특징 맵은 입력 이미지보다 작아집니다. 반면, Same 패딩을 사용하면 출력 특징 맵이 입력 이미지와 동일한 크기를 가지게 됩니다.\n",
    "##### 출력 텐서:\n",
    "- 필터를 적용한 후, 각 필터마다 3D 출력(특징 맵)이 생성됩니다. \n",
    "- 입력 이미지가 (N=1, H=32, W=32, C=3) 크기라고 가정합시다(배치 크기 1, 크기 32x32, 색상 채널 3). 여기에 (3, 3, 3) 크기의 10개의 필터를 사용하고, 스트라이드는 1, 패딩은 1로 설정했다고 할 때:\n",
    "  - 출력 높이와 출력 너비: Same 패딩을 사용했기 때문에 입력 이미지의 크기와 동일하게 H_out = 32, W_out = 32가 됩니다.\n",
    "  - 출력 채널 수: 필터의 개수가 10이므로, 출력 텐서의 깊이는 K = 10입니다.\n",
    "  - 따라서 최종 출력 텐서의 형태는 (1, 32, 32, 10)이 됩니다.\n",
    "\n",
    "##### 요약:\n",
    "- 합성곱 층은 필터를 사용해 입력 데이터에서 특징을 추출합니다.\n",
    "- 각 필터는 이미지에서 특정 패턴을 감지합니다.\n",
    "- 출력 텐서의 크기는 필터 크기, 스트라이드, 패딩, 필터의 개수에 따라 달라집니다.\n",
    "- 이와 같은 방식으로 합성곱 층이 이미지 데이터를 처리하고, 중요한 특징들을 추출하여 더 깊은 네트워크에서 활용할 수 있도록 돕습니다.\n",
    "\n",
    "--- \n",
    "\n",
    "### 출력 텐서가 뭐야?\n",
    "\n",
    "- 출력 텐서(Output Tensor)는 신경망에서 입력 데이터가 여러 층을 거쳐 처리된 후에 각 층에서 생성되는 결과 데이터입니다. 텐서는 다차원 배열을 의미하는데, 주로 이미지나 시계열 데이터처럼 복잡한 구조를 다룰 때 사용됩니다. 합성곱 신경망(CNN)에서는 입력 이미지가 합성곱 연산을 거쳐 다양한 특징을 추출한 후, 이 특징들을 포함하는 출력 텐서가 생성됩니다. 간단히 말하자면, 출력 텐서는 신경망의 각 층에서 계산된 결과 데이터로, 주어진 입력이 처리된 후 나온 결과값을 담고 있는 다차원 배열입니다.\n",
    "  \n",
    "- 예시로 설명:\n",
    "  - 입력 텐서: 예를 들어, 입력 이미지는 (N, H, W, C) 형태로 주어집니다.\n",
    "    - N: 배치 크기 (이미지 개수)\n",
    "    - H: 이미지의 높이\n",
    "    - W: 이미지의 너비\n",
    "    - C: 색상 채널 수 (예: RGB라면 3)\n",
    "  - 합성곱 층을 지나면 :\n",
    "    - 여러 개의 필터(커널)가 이미지를 스캔하면서 특징을 추출합니다.\n",
    "    - 각 필터는 이미지에서 특정 패턴(예: 모서리, 텍스처 등)을 감지합니다.\n",
    "    - 이 특징 맵(feature map)은 출력 텐서입니다.\n",
    "    - 필터가 하나의 이미지에서 특정 패턴을 감지하고, 그 결과를 3D 배열(H_out, W_out, K) 형태로 저장합니다.\n",
    "    - H_out과 W_out: 필터를 적용한 후 이미지의 새로운 높이와 너비\n",
    "    - K: 사용한 필터의 개수 (각각의 필터는 하나의 특징 맵을 생성하므로)\n",
    "   \n",
    "---\n",
    "``` \n",
    "Transposed Convolution (For Segmentation, Super-resolution,...)\n",
    "Alternative names in other resources.\n",
    "- Fractionally-strided convolution\n",
    "- Deconvolution\n",
    "Does not use a predefined interpolation method\n",
    "```\n",
    "### 위 부분에 대한 내용을 한글로 알려줘\n",
    "- Transposed Convolution (역합성곱)은 이미지 분할(Segmentation)이나 초해상도(Super-resolution) 등 다양한 작업에서 사용되는 기법입니다. 이를 통해 입력 이미지를 업샘플링(Upsampling)하여 크기를 늘리거나 더 높은 해상도의 이미지를 생성할 수 있습니다.\n",
    "- 완전 합성곱 네트워크는 위치 정보가 보존된다는 장점에도 다음과 같은 단점이 있습니다.\n",
    "  - 여러 단계의 합성곱층과 풀링층을 거치면서 해상도가 낮아집니다.\n",
    "  - 낮아진 해상도를 복원하기 위해 업 샘플링 방식을 사용하기 때문에 이미지의 세부 정보들을 잃어버리는 문제가 발생합니다.\n",
    "- 이러한 문제를 해결하기 위해 역합성곱 네트워크를 도입한 것이 합성곱 & 역합성곱 네트워크(convolutional & deconvolutional network)입니다. 역합성곱은 CNN의 최종 출력 결과를 원래의 입력 이미지와 같은 크기를 만들고 싶을 때 사용합니다. 시멘틱 분할(semantic segmentation) 등에 활용할 수 있으며, 역합성곱은 업 샘플링(upsampling) 등으로도 부릅니다.\n",
    "- 다른 이름들:\n",
    "  - Fractionally-strided Convolution (분수 스트라이드를 사용한 합성곱)\n",
    "  - Deconvolution (역합성곱)\n",
    "  - 이 기법들은 모두 Transposed Convolution을 가리키며, 때로는 다르게 불리기도 합니다. 예를 들어, Deconvolution이라는 이름은 역합성곱을 의미하지만, 정확히 말하면 Transposed Convolution은 일반적인 합성곱의 \"전치(transpose)\" 연산을 의미하는 것이며, 실제로는 기존의 합성곱 연산을 뒤집는 방식으로 작동합니다.\n",
    "- 기존의 보간법 사용하지 않음:\n",
    "  - Transposed Convolution은 미리 정의된 보간 방법(interpolation method)을 사용하지 않고, 학습 가능한 필터를 통해 업샘플링을 수행합니다. 즉, 업샘플링을 통해 이미지 크기를 증가시키는 방식이 전통적인 보간법(예: 최근접 이웃, 선형 보간)과는 다릅니다. 대신, 네트워크가 학습을 통해 최적의 가중치(필터)를 찾아내고, 이를 통해 이미지를 업샘플링합니다. 이는 네트워크가 데이터에 맞춰 최적화된 방식으로 이미지를 확장할 수 있게 도와줍니다.\n",
    "- 요약:\n",
    "  - Transposed Convolution은 이미지를 업샘플링할 때 사용하는 기법으로, Deconvolution 또는 Fractionally-strided Convolution이라는 이름으로도 불립니다. 이 기법은 전통적인 보간법을 사용하지 않고, 학습 가능한 필터를 통해 최적의 업샘플링을 수행합니다.\n",
    "\n",
    "---\n",
    "\n",
    "### octave convolution에 대해서 설명해줘\n",
    "- Octave Convolution은 최근 컴퓨터 비전 및 딥러닝 분야에서 등장한 효율적인 합성곱 기법 중 하나입니다. 이 기법은 합성곱 신경망(CNN)에서 계산 비용을 줄이면서 성능을 유지하거나  향상시키기 위한 방법으로 제안되었습니다. Octave Convolution은 기존의 합성곱 연산을 주파수 대역(low-frequency와 high-frequency)으로 나누어 처리하는 방식을 채택합니다.\n",
    "- Octave Convolution의 주요 아이디어\n",
    "  - Octave Convolution의 핵심 아이디어는 이미지의 저주파(low-frequency)와 고주파(high-frequency) 성분을 분리하고, 이를 다르게 처리하는 것입니다. 이미지의 저주파 성분은 주로 이미지의 전반적인 형태나 배경을 나타내고, 고주파 성분은 이미지의 세부 사항이나 엣지 등을 나타냅니다. 일반적으로, 이미지의 저주파 성분은 더 중요하고, 고주파 성분은 상대적으로 덜 중요할 수 있습니다. Octave Convolution은 이 두 성분을 분리하여 별도로 처리함으로써 계산 효율성을 높이고, 불필요한 계산을 줄일 수 있습니다. 이를 통해 연산량을 감소시키면서도 성능을 유지하거나 개선할 수 있습니다.\n",
    "- 작동 원리\n",
    "  - Octave Convolution은 주파수 대역을 저주파와 고주파로 나누고, 각 대역에 대해 별도로 합성곱 연산을 적용합니다. 이 과정에서 저주파 성분은 더 낮은 해상도로 처리하고, 고주파 성분은 더 높은 해상도로 처리하여 계산을 효율적으로 처리합니다.\n",
    "- 주파수 대역 분리:\n",
    "  - 이미지를 저주파 성분(low-frequency)과 고주파 성분(high-frequency)으로 분리합니다. 일반적으로, 이미지를 한 번의 하이패스 필터(high-pass filter)와 로우패스 필터(low-pass filter)를 통해 나눕니다.\n",
    "  - 저주파 처리: 저주파 성분은 저해상도로 처리되며, 이는 이미지의 전반적인 형태와 배경을 다룹니다. 이를 통해 계산 비용을 줄입니다.\n",
    "  - 고주파 처리: 고주파 성분은 고해상도로 처리되며, 이미지의 세부 사항이나 엣지를 다룹니다.\n",
    "  - 재합성: 마지막으로, 저주파와 고주파 성분을 다시 합쳐 최종 출력을 만듭니다.\n",
    "- 장점\n",
    "  - 효율성: 주로 저주파 성분은 많은 정보가 없거나 덜 중요하기 때문에 저해상도로 처리할 수 있습니다. 고주파 성분만 더 세밀하게 처리하면 연산량을 크게 줄일 수 있습니다.\n",
    "  - 성능 유지: 이미지의 중요한 정보가 주로 저주파 성분에 포함되어 있기 때문에, 저주파 성분에 집중하면서도 성능을 유지할 수 있습니다.\n",
    "  - 연산 비용 절감: 고해상도에서 처리할 필요가 없는 정보를 저해상도에서 처리함으로써 계산 비용을 절감할 수 있습니다.\n",
    "  - 예시: 이미지 처리\n",
    "  - 기존 CNN에서는 전체 이미지를 하나의 해상도로 처리하고, 이 과정에서 모든 주파수 성분을 다루게 됩니다. 이때 계산량이 많고, 연산 속도가 느려질 수 있습니다.\n",
    "  - Octave Convolution에서는 이미지를 저주파와 고주파로 나누어 각각 다르게 처리하기 때문에, 저주파 성분은 저해상도로, 고주파 성분은 고해상도로 처리하게 되어 계산이 훨씬 효율적으로 이루어집니다.\n",
    "- Octave Convolution의 적용 분야\n",
    "  - Octave Convolution은 주로 이미지 분할, 초해상도, 이미지 복원 등에서 사용되며, 특히 연산 비용이 중요한 문제에서 유용하게 사용될 수 있습니다. 예를 들어, 실시간 시스템이나 모바일 장치와 같은 자원 제약이 있는 환경에서 계산 효율성을 높이기 위해 활용됩니다.\n",
    "\n",
    "---\n",
    "### CNNs for Classification 의 안에서 일어나는 세부 절차를 알려줘\n",
    "- CNNs(Convolutional Neural Networks)는 주로 이미지 분류와 같은 작업을 수행하기 위해 설계된 신경망입니다. CNN을 사용한 분류(Classification) 작업에서는 입력 이미지가 여러 층을 거쳐 처리되며, 각 층에서는 이미지에서 특정 특징을 추출하거나 변환하는 작업이 이루어집니다. 이 과정을 통해 이미지는 점차 추상적인 표현으로 변환되고, 마지막에는 분류 결과가 나옵니다.\n",
    "- 다음은 CNN을 이용한 분류에서 일어나는 주요 절차를 단계별로 설명한 것입니다:\n",
    "  1. 입력 이미지 준비\n",
    "     - CNN 모델은 먼저 입력 데이터를 받습니다. 일반적으로 이미지 데이터가 주어집니다.\n",
    "     - 예를 들어, 28x28 크기의 흑백 이미지나 224x224 크기의 RGB 이미지를 사용할 수 있습니다.\n",
    "     - 입력 이미지는 (N, H, W, C) 형태의 4D 텐서로 표현됩니다.\n",
    "     - N: 배치 크기 (한 번에 처리할 이미지 개수)\n",
    "     - H: 이미지의 높이\n",
    "     - W: 이미지의 너비\n",
    "     - C: 이미지의 채널 수 (흑백은 1, RGB는 3)\n",
    "  2. 합성곱 층(Convolutional Layer)\n",
    "     - 합성곱 층은 이미지에서 지역적 특징을 추출하는 역할을 합니다. 합성곱 필터(또는 커널)가 이미지 위를 슬라이딩하면서 내적을 계산하고, 이를 통해 특징 맵(feature map)을 생성합니다. 여러 개의 필터를 사용하여 다양한 특징을 추출합니다. 예를 들어, 엣지, 텍스처, 모양 등을 탐지할 수 있습니다. 이 과정은 이미지의 중요한 특징을 추출하고, 점차 추상적인 특징으로 변환해 줍니다.\n",
    "  3. 활성화 함수(Activation Function)\n",
    "     - 합성곱 연산 후, 활성화 함수(주로 ReLU(Rectified Linear Unit))가 적용됩니다. ReLU 함수는 음수를 0으로 변환하고, 양수는 그대로 유지하는 함수로, 신경망에서 비선형성을 추가하여 더 복잡한 패턴을 학습할 수 있도록 합니다. 이 활성화 함수는 비선형 변환을 통해 모델이 복잡한 데이터 패턴을 학습할 수 있게 도와줍니다.\n",
    "  4. 풀링 층(Pooling Layer)\n",
    "     - 풀링 층은 특징 맵의 크기를 줄이는 데 사용됩니다. 이를 통해 계산 비용을 줄이고, 위치 불변성을 얻을 수 있습니다. 가장 많이 사용되는 풀링 방법은 최대 풀링(Max Pooling)으로, 각 풀링 영역에서 최대값을 선택합니다. 예를 들어, 2x2 영역에서 최대값을 뽑는 방식으로, 특징 맵의 크기를 절반으로 줄일 수 있습니다.\n",
    "  5. 다층 합성곱 층과 풀링 층 반복\n",
    "     - 일반적으로 여러 개의 합성곱 층과 풀링 층이 스택(stack) 형태로 쌓입니다. 초기 합성곱 층은 저수준 특징(예: 엣지, 선)을 추출하고, 깊은 층에서는 고수준 특징(예: 객체의 형태, 얼굴 인식 등)을 추출합니다. 풀링 층은 점차 특징 맵의 크기를 줄여서 계산 효율성을 높입니다.\n",
    "  6. 완전 연결 층(Fully Connected Layer)\n",
    "     - 합성곱 및 풀링 층을 지나면서 추출된 특징들은 1D 벡터로 평탄화(flatten)됩니다. 평탄화된  벡터는 완전 연결 층(Fully Connected Layer, FC)에 입력됩니다. FC 층은 이미지의 클래스를 예측하는 역할을 합니다. FC 층은 일반적인 신경망의 구조와 같으며, 각 뉴런은 이전 층의 모든 뉴런과 연결됩니다.\n",
    "  7. 출력층(Output Layer)\n",
    "     - 마지막 완전 연결 층에서는 소프트맥스(softmax) 함수 또는 시그모이드(sigmoid) 함수가 적용됩니다. 소프트맥스는 다중 클래스 분류에서 각 클래스에 대한 확률을 출력합니다. 예를 들어, 10개의 클래스가 있다면 각 클래스에 대한 확률을 계산하여 가장 높은 확률을 가진 클래스를 예측합니다. 시그모이드는 이진 분류에서 사용되며, 0 또는 1의 두 가지 클래스 중 하나를 예측합니다.\n",
    "  8. 출력(예측)\n",
    "     - 출력층에서 나온 값은 모델이 예측한 클래스입니다. 예를 들어, 고양이와 개를 구분하는 모델이라면, 출력층에서 고양이에 대한 확률이 높으면 고양이로 분류하고, 개에 대한 확률이 높으면 개로 분류합니다.\n",
    "  9. 손실 함수(Loss Function)\n",
    "     - 모델의 예측 결과와 실제 레이블(ground truth) 사이의 차이를 계산하는 손실 함수가 있습니다. 보통 크로스 엔트로피(cross-entropy) 손실 함수가 사용됩니다. 손실 함수 값이 작을수록 모델의 예측이 실제 값과 가까워집니다.\n",
    "  10. 역전파(Backpropagation) 및 학습\n",
    "     - 모델이 예측한 결과와 실제 값의 차이를 기반으로 역전파(backpropagation)를 사용하여 가중치를 업데이트합니다. 경사 하강법(Gradient Descent) 또는 Adam과 같은 최적화 알고리즘을 사용하여 모델의 가중치를 조정하고, 학습을 통해 오차를 최소화합니다.\n",
    "\n",
    "- CNN의 분류 절차 요약:\n",
    "  - 입력 이미지를 받아서,\n",
    "  - 합성곱 층에서 특징을 추출하고,\n",
    "  - 활성화 함수(ReLU)로 비선형성을 추가하고,\n",
    "  - 풀링 층에서 크기를 축소하며,\n",
    "  - 여러 층을 반복하면서 점차 고수준 특징을 학습하고,\n",
    "  - 평탄화된 벡터를 완전 연결 층에 입력하고,\n",
    "  - 마지막으로 출력층에서 클래스 확률을 예측합니다.\n",
    "  - 손실 함수를 사용해 예측과 실제 차이를 계산하고, 이를 통해 가중치를 업데이트하여 모델을 학습시킵니다.\n",
    "  - 이 과정은 훈련과정 동안 반복되며, 모델이 이미지 분류를 잘 수행할 수 있도록 학습됩니다.\n",
    "---\n",
    "```\n",
    "Comparison: FC vs CNN\n",
    "\n",
    "Fully Connected\n",
    "- Input data: image 10x10 => 100 numbers \n",
    "- First Layer: 32 nodes => 100 weights\n",
    "- Total => 3200 weights\n",
    "  \n",
    "Convolutional \n",
    "- Input data: image 10x10 => 100 numbers\n",
    "- First Layer: 32 conv, kernels 3x3 => 9 weights each\n",
    "- Total => 32 x 9 = 288 weights\n",
    "```\n",
    "### 위 내용을 한글로 풀어서 설명해줘\n",
    "Fully Connected (FC)와 Convolutional (CNN) 비교는 각 신경망 구조에서 입력 데이터 처리 방식과 가중치 수에 따른 차이를 보여주는 좋은 예시입니다. 이를 한글로 풀어서 설명해드리겠습니다.\n",
    "\n",
    "1. Fully Connected (FC)\n",
    "   - 완전 연결층은 모든 입력이 모든 뉴런에 연결되는 구조입니다. 입력 데이터의 각 요소가 모두 연결되어 다차원 행렬로 변환되고, 그 후에 각 뉴런에 연결된 가중치들을 계산하게 됩니다.\n",
    "   - 예시:\n",
    "   - 입력 데이터: 이미지 크기가 10x10이라면, 총 100개의 값(픽셀)이 주어집니다.\n",
    "   - 예를 들어, 이미지를 10x10 크기로 표현한다고 했을 때, 이 100개의 값을 하나씩 처리해야 하므로 입력은 100개의 숫자가 됩니다.\n",
    "   - 첫 번째 층: 첫 번째 완전 연결층에 32개의 노드가 있다고 가정합니다. 이 노드들은 입력 이미지의 모든 값과 연결됩니다.\n",
    "   - 각 노드는 100개의 입력 값(픽셀)과 연결되므로, 각 노드에 대해 100개의 가중치가 존재합니다.\n",
    "   - 총 가중치: 32개의 노드 각각에 100개의 가중치가 연결되므로, 전체 가중치는 32 x 100 = 3200개의 가중치가 필요합니다.\n",
    "2. Convolutional (CNN)\n",
    "   - 합성곱 신경망(CNN)은 이미지와 같은 데이터를 처리하는 데 효과적인 신경망입니다. CNN에서는 합성곱 필터(커널)를 사용해 입력 이미지의 특정 부분만을 처리하고, 그 결과로 나온 특징 맵을 바탕으로 학습합니다. 이렇게 하면 가중치의 수가 현저히 줄어듭니다.\n",
    "   - 예시:\n",
    "   - 입력 데이터: 이미지 크기가 10x10이고, 여전히 100개의 숫자로 표현됩니다.\n",
    "   - 첫 번째 층: 첫 번째 합성곱 층에서 32개의 필터를 사용한다고 가정합니다. 각 필터는 3x3 크기입니다.\n",
    "   - 각 필터는 3x3 = 9개의 가중치로 구성됩니다.\n",
    "   - 총 가중치: 32개의 필터 각각에 대해 9개의 가중치가 존재하므로, 전체 가중치는 32 x 9 = 288개의 가중치가 필요합니다.\n",
    "3. FC vs CNN 비교\n",
    "|구성 요소|FC(완전 연결)|CNN(합성곱 신경망)|\n",
    "|-------|-----------|--------------|\n",
    "|입력 데이터 크기|10x10 이미지 -> 100개의 숫자|10x10 이미지 -> 100개의 숫자|\n",
    "|첫 번째 층|32개의 노드, 각 노드는 100개의 입력과 연결됨 | 32개의 필터(3x3 크기), 각 필터는 9개의 가중치|\n",
    "|가중치 수|3200개의 가중치(32 x 100) |288개의 가중치 (32 x 9)|\n",
    " \n",
    "- 요약:\n",
    "  - FC는 모든 입력값이 모든 노드와 연결되어 있어, 가중치의 수가 매우 많습니다.\n",
    "  - 이 예시에서는 100개의 입력 값에 대해 3200개의 가중치가 필요합니다.\n",
    "  - CNN은 합성곱 필터를 사용해 입력 이미지에서 중요한 특징만을 추출하고, 필터 크기가 작은 덕분에 가중치 수가 적습니다. 이 예시에서는 32개의 필터를 사용해 288개의 가중치만 필요합니다.\n",
    "  - 결론적으로, FC는 가중치가 많고 계산량이 많아 효율성이 떨어질 수 있지만, CNN은 필터를 사용해 가중치 수를 줄이고, 효율적으로 이미지를 처리할 수 있어 계산 비용을 절감하는 장점이 있습니다.\n",
    "\n",
    "---\n",
    "```\n",
    "LeNet-5, AlexNet, GoogLeNet, ResNet\n",
    "```\n",
    "### 위에 열거된 거에 대해서 설명해줘\n",
    "LeNet-5, AlexNet, GoogLeNet, 그리고 ResNet은 딥러닝 분야에서 중요한 역할을 한 CNN 아키텍처들입니다. 각 모델은 컴퓨터 비전 분야에서의 성능 향상과 혁신적인 접근 방식을 제시했으며, 이미지 분류, 객체 인식 등 다양한 작업에서 뛰어난 성능을 보여주었습니다. 각 모델에 대해 자세히 설명드리겠습니다.\n",
    "  \n",
    "1. LeNet-5 (1998)\n",
    "   - LeNet-5는 Yann LeCun이 제안한 초기 합성곱 신경망(CNN) 아키텍처로, 손글씨 인식(특히 MNIST 데이터셋)에서 뛰어난 성능을 발휘한 모델입니다. LeNet-5는 CNN의 초기 형태로, 현대적인 CNN 구조의 기본적인 아이디어를 포함하고 있습니다.\n",
    "   - LeNet-5 아키텍처:\n",
    "   - 입력 이미지: 32x32 픽셀 크기의 이미지 (MNIST는 28x28 크기지만, LeNet-5에서는 이를 32x32로 패딩 처리하여 사용)\n",
    "   - 합성곱 층: 첫 번째 합성곱 층은 6개의 5x5 필터를 사용하고, 두 번째 합성곱 층은 16개의 5x5 필터를 사용합니다.\n",
    "   - 풀링 층: 서브샘플링(subsampling) 또는 풀링 층은 이미지의 공간적 차원을 줄여주는 역할을 하며, LeNet-5에서는 평균 풀링을 사용합니다.\n",
    "   - 완전 연결 층: 두 개의 완전 연결 층이 있으며, 첫 번째 FC 층은 120개 노드, 두 번째는 84개 노드로 구성됩니다.\n",
    "   - 출력층: 10개 클래스를 예측하는 소프트맥스 층을 사용하여, 손글씨 숫자(0~9)를 분류합니다.\n",
    "   - 특징:\n",
    "   - 간단한 구조로 CNN의 기본 개념을 소개하고, 손글씨 숫자 분류에서 큰 성공을 거둔 모델입니다.\n",
    "   - 현재의 CNN보다 깊이가 얕고, 효율적이지만, 그 당시에는 혁신적인 아키텍처로 간주되었습니다.\n",
    "     \n",
    "2. AlexNet (2012)\n",
    "   - AlexNet은 ImageNet 대회에서 압도적인 성능으로 우승한 모델로, 딥러닝의 부흥을 이끈 혁신적인 아키텍처입니다. AlexNet은 ReLU 활성화 함수와 드롭아웃(dropout), GPU 활용 등 다양한 기법을 도입하여 큰 성과를 거두었습니다.\n",
    "   - AlexNet 아키텍처:\n",
    "   - 입력 이미지: 224x224 크기의 컬러 이미지 (RGB)\n",
    "   - 합성곱 층: 5개의 합성곱 층이 있으며, 첫 번째 합성곱 층은 11x11 필터, 두 번째는 5x5 필터 등 큰 필터 크기를 사용합니다.\n",
    "   - 풀링 층: Max pooling이 적용되어, 이미지의 크기를 줄이면서 중요한 특징을 유지합니다.\n",
    "   - 완전 연결 층: 3개의 완전 연결층이 있으며, 두 번째와 세 번째 FC 층은 각각 4096개의 노드를 가집니다.\n",
    "   - 출력층: 1000개의 클래스를 예측하는 소프트맥스 출력층.\n",
    "   - 특징:\n",
    "   - ReLU 활성화 함수 도입: 기존의 sigmoid나 tanh보다 훈련 속도가 빠르고 더 좋은 성능을 보였습니다.\n",
    "   - GPU 병렬 처리를 활용하여, 대규모 데이터셋에서 빠르게 학습할 수 있었습니다.\n",
    "   - 드롭아웃 기법을 통해 과적합을 방지하고, 모델의 일반화 능력을 향상시켰습니다.\n",
    "   - ImageNet 대회에서 우승하며 CNN을 본격적으로 주목받게 한 모델입니다.\n",
    "  \n",
    "3. GoogLeNet (2014)\n",
    "   - GoogLeNet은 Google의 Inception 아키텍처를 기반으로 한 모델로, 더 깊고 복잡한 모델을 만들기 위해 효율성을 추구한 모델입니다. GoogLeNet은 Inception 모듈을 통해 다양한 크기의 필터를 동시에 적용하여 연산 효율성과 성능을 동시에 개선했습니다.\n",
    "   - GoogLeNet 아키텍처:\n",
    "   - 입력 이미지: 224x224 크기의 이미지\n",
    "   - Inception 모듈: GoogLeNet의 핵심 아이디어는 Inception 모듈로, 이 모듈에서는 여러 크기의 합성곱 필터(1x1, 3x3, 5x5)를 동시에 적용하고, 그 결과를 병합(concatenate)하여 계산량을 줄이고, 더 많은 특징을 추출합니다.\n",
    "   - 합성곱 층: GoogLeNet은 22층의 깊이를 가지며, 각 층에서 Inception 모듈을 적용하여 학습합니다.\n",
    "   - 풀링 층: 평균 풀링과 Max Pooling이 혼합되어 사용됩니다.\n",
    "   - 출력층: 1000개의 클래스를 예측하는 소프트맥스 출력층.\n",
    "   - 특징:\n",
    "   - Inception 모듈을 통해 효율적인 계산을 달성하고, 모델 크기를 줄이며 성능을 높였습니다.\n",
    "   - 네트워크 깊이를 늘리되 계산 효율성을 유지하는 방식으로 성능을 개선했습니다.\n",
    "   - GoogLeNet은 정규화와 병렬화를 통해 모델의 계산 성능을 최적화하고, 파라미터 수를 줄였습니다.\n",
    "     \n",
    "4. ResNet (2015)\n",
    "   - ResNet은 Residual Network의 약자로, 딥러닝에서 심층 신경망의 훈련을 가능하게 만든 혁신적인 모델입니다. Residual Connection을 도입하여 기존의 네트워크 깊이 한계를 극복하고, 수백 개의 층으로 깊어진 네트워크를 성공적으로 훈련시킬 수 있었습니다.\n",
    "   - ResNet 아키텍처:\n",
    "   - 입력 이미지: 224x224 크기의 이미지\n",
    "   - Residual Block: ResNet의 핵심은 Residual Block입니다. 이 블록에서는 shortcut connection(스킵 연결)을 사용하여 입력을 출력에 더하는 방식으로, 기울기 소실 문제를 해결하고, 심층 신경망 훈련을 가능하게 했습니다.\n",
    "   - 합성곱 층: 다양한 깊이(예: ResNet-50, ResNet-101, ResNet-152)의 모델들이 존재하며, 각 모델은 Residual Block을 여러 번 반복한 구조입니다.\n",
    "   - 출력층: 1000개의 클래스를 예측하는 소프트맥스 출력층.\n",
    "   - 특징:\n",
    "   - Residual Connection을 통해 더 깊은 네트워크를 효과적으로 훈련시킬 수 있었으며, 기울기 소실 문제를 해결했습니다.\n",
    "   - 100층 이상의 깊이를 가지면서도 높은 성능을 발휘하며, ImageNet 대회에서 뛰어난 성능을 보였습니다.\n",
    "   - ResNet은 현재 많은 고급 네트워크에서 기본 아키텍처로 사용되고 있으며, 딥러닝 연구와 응용에서 큰 영향을 미쳤습니다.\n",
    "\n",
    "#### 요약\n",
    "   - 모델특징발표 년도\n",
    "   - LeNet-5\t최초의 CNN 모델, 손글씨 인식(MNIST)에 사용, 합성곱층과 풀링층을 활용한 구조\t1998\n",
    "   - AlexNet\tImageNet 대회에서 우승, ReLU 활성화 함수, GPU 활용, 드롭아웃 등을 도입하여 학습 속도와 성능 향상\t2012\n",
    "   - GoogLeNet\tInception 모듈을 사용하여 다양한 크기의 필터를 병렬로 적용, 효율적인 연산과 성능 개선\t2014\n",
    "   - ResNet\tResidual Connection을 도입하여 심층 네트워크 훈련 가능, 기울기 소실 문제 해결, 매우 깊은 네트워크(100층 이상)에서 성능 발휘\t2015\n",
    "   - 이들 모델은 컴퓨터 비전과 딥러닝 연구에서 중요한 발전을 나타내며, 이미지 분류 및 다른 여러 작업에서 혁신적 성과를 이뤘습니다.\n",
    "\n",
    "---\n",
    "\n",
    "### CapsNet or Capsule Network (Out of Scope- Highly recommended to read) 대해서 알려줘\n",
    "- CapsNet (Capsule Network) 또는 Capsule Networks는 Geoffrey Hinton 교수와 그의 연구팀이 제안한 혁신적인 신경망 아키텍처로, 기존의 합성곱 신경망(CNN)의 한계를 극복하기 위해 개발되었습니다. Capsule Network의 주요 아이디어는 **캡슐(capsule)**이라는 새로운 계산 단위를 도입하여, 객체의 공간적 관계와 자세를 더 잘 학습하고 표현하는 것입니다. CapsNet은 기존 CNN이 기하학적 변환(예: 회전, 크기 조정, 변형)에 민감한 문제를 해결하려는 시도로 등장했으며, 특히 대규모 변형에 대한 일반화 능력을 개선하려는 목적을 가지고 있습니다.\n",
    "- Capsule Network의 핵심 아이디어\n",
    "  - Capsule Network의 가장 큰 특징은 캡슐(capsule)이라는 새로운 계산 단위를 도입한 점입니다. 전통적인 뉴런은 단일 스칼라 값을 출력하는 반면, 캡슐은 벡터 또는 행렬을 출력합니다. 이를 통해, 캡슐은 객체의 속성(예: 방향, 크기, 각도 등)과 객체의 변형 관계를 모델링할 수 있습니다.\n",
    "\n",
    "1. 캡슐 (Capsule)\n",
    "   - 캡슐은 여러 뉴런들이 모여서 구성된 소형 신경망으로, 객체의 속성과 변형 관계를 포함한 벡터를 출력합니다.\n",
    "   - 각 캡슐은 객체의 부분적인 정보를 학습하고, 다른 캡슐과 연결하여 전체 객체의 구성을 이해할 수 있도록 합니다.\n",
    "2. Routing by Agreement\n",
    "   - Capsule Network에서 중요한 개념은 Routing by Agreement입니다. 이 방식은 위치 관계와 구성 요소 간의 관계를 학습하는 데 사용됩니다.\n",
    "   - 간단히 말해, 하위 캡슐이 상위 캡슐로 정보를 보낼 때, 정보가 얼마나 잘 일치하는지 합의를 통해 전달 경로를 결정합니다.\n",
    "   - 이 과정에서 캡슐들이 상호작용하며, 서로 다른 객체의 변형을 효과적으로 처리할 수 있습니다.\n",
    "3. Dynamic Routing\n",
    "   - 동적 라우팅 (Dynamic Routing)은 하위 캡슐이 상위 캡슐에 정보를 전달할 때, 각 캡슐 간의 유사도를 기반으로 전달 경로를 선택하는 방식입니다.\n",
    "   - 이 방식은 학습을 통해 캡슐들 간의 상호작용을 최적화하며, 기하학적 변형에 대한 강인성을 높이는 데 기여합니다.\n",
    "\n",
    "- CapsNet의 특징 및 장점\n",
    "  - 공간적 관계 유지\n",
    "    - CNN은 풀링 층을 통해 공간적 정보를 감소시키지만, CapsNet은 캡슐을 사용하여 객체의 자세와 공간적 관계를 보존합니다. 이를 통해 회전, 기울기, 크기 변환 등에 강한 모델을 만들 수 있습니다.\n",
    "  - 기하학적 변형에 강한 일반화\n",
    "    - CapsNet은 객체 변형에 대한 민감도를 줄이고, 회전, 크기 조정, 변형 등에 대해 잘 일반화됩니다. 기존 CNN은 전통적인 풀링 기법 때문에 이미지의 기하학적 변형에 약하지만, CapsNet은 캡슐을 통해 이를 해결합니다.\n",
    "  - 효율적인 파라미터 수\n",
    "    - CapsNet은 적은 수의 파라미터로 더 많은 정보를 효율적으로 처리할 수 있습니다. 이는 CNN의 풀링 층과 달리, 객체의 자세와 변형을 효과적으로 학습할 수 있기 때문입니다.\n",
    "  - 다중 객체 인식\n",
    "    - 캡슐 네트워크는 객체 간의 관계를 잘 모델링할 수 있어, 다중 객체 인식에서 기존 모델보다 더 뛰어난 성능을 발휘할 수 있습니다.\n",
    "  - CapsNet의 아키텍처\n",
    "    - Capsule Network의 기본 구조는 캡슐 계층(capsule layer)로 구성되며, 다음과 같은 주요 층을 포함합니다.\n",
    "      - 입력 계층: 입력 이미지를 받아들여 첫 번째 합성곱 층을 통해 특징을 추출합니다.\n",
    "      - 캡슐 계층: 이 계층에서는 부분적 특징을 학습하는 캡슐들이 모여서 전체적인 객체의 자세와 공간적 관계를 학습합니다.\n",
    "      - 리소팅 계층: 동적 라우팅을 통해, 각 하위 캡슐이 상위 캡슐에 정보를 전달하면서, 서로의 관계를 최적화하고, 객체를 잘 표현합니다.\n",
    "      - 출력 계층: 객체의 존재 여부와 객체의 자세를 출력하는 최종 계층입니다.\n",
    "  - CapsNet의 한계와 도전 과제\n",
    "    - 컴퓨팅 자원:\n",
    "      - 동적 라우팅 과정에서 복잡한 계산이 필요하므로, 많은 계산 자원을 요구할 수 있습니다. 이는 모델 훈련 속도를 저하시킬 수 있습니다.\n",
    "    - 대규모 데이터셋에서의 한계:\n",
    "      - CapsNet은 다양한 데이터셋에서 좋은 성능을 보이지만, 대규모 데이터셋에 대해서는 성능이 제한적일 수 있습니다. 모델의 확장성이나 큰 데이터셋에 대한 일반화에서 도전이 있을 수 있습니다.\n",
    "    - 구현의 복잡성:\n",
    "      - 기존의 CNN과 달리, 캡슐 네트워크는 동적 라우팅과 캡슐 단위를 구현하는 것이 비교적 복잡하고, 기술적 난이도가 높습니다.\n",
    "  - Capsule Network의 응용 분야\n",
    "    - Capsule Networks는 기하학적 변형에 강한 모델로, 다양한 분야에서 유망한 성능을 발휘할 수 있습니다. 대표적인 응용 분야는 다음과 같습니다:\n",
    "      - 객체 인식:\n",
    "        - 물체의  자세 변환에 민감하지 않고, 물체의 공간적 관계를 잘 이해할 수 있어, 다양한 객체 인식 문제에서 강력한 성능을 발휘할 수 있습니다.\n",
    "      - 이미지 분류:\n",
    "        - 회전, 크기 변환, 기울기 등 다양한 기하학적 변형에 강한 일반화 능력을 갖추고 있어, 복잡한 이미지 분류 문제에서 유리합니다.\n",
    "      - 로봇 비전:\n",
    "        - 로봇 비전 시스템에서 물체의 위치나 자세를 정확하게 인식하고, 환경의 변형을 잘 처리할 수 있습니다.\n",
    "      - 의료 영상 분석:\n",
    "        - 의료 영상에서 질병을 인식하는 데 있어서, 물체의 형태와 공간적 관계를 정확하게 파악할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015ad805-1a89-4c6a-9f4e-cbd6f5361061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
