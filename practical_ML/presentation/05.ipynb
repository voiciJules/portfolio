{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28e3ca9b-a480-4f88-9184-ed3b8db0c6ca",
   "metadata": {},
   "source": [
    "# Module 5. Representations, Autoencoders and Generative Models\n",
    "\n",
    "## âœ… Autoencoderê°€ ë­ í•˜ëŠ” ê±°ì•¼?\n",
    "\n",
    "**í•œë§ˆë””ë¡œ ë§í•˜ë©´:**  \n",
    "ğŸ‘‰ *\"ì…ë ¥ì„ ì••ì¶•í•´ì„œ ë‹¤ì‹œ ë˜‘ê°™ì´ ë³µì›í•´ ë³´ëŠ” ë„¤íŠ¸ì›Œí¬\"*\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ ì¡°ê¸ˆ ë” í’€ì–´ì„œ\n",
    "\n",
    "#### 1ï¸âƒ£ ì…ë ¥ ë°ì´í„°ë¥¼ ë„£ëŠ”ë‹¤\n",
    "ì˜ˆ: ê³ ì–‘ì´ ì‚¬ì§„, ìˆ«ì ì´ë¯¸ì§€ ë“±\n",
    "\n",
    "#### 2ï¸âƒ£ \"ì ì¬ ê³µê°„(latent space)\"ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ì•„ì£¼ ì‘ì€ ê³µê°„ìœ¼ë¡œ ì••ì¶•í•œë‹¤\n",
    "- ë°ì´í„°ë¥¼ ì‘ê³  ê°„ë‹¨í•˜ê²Œ í‘œí˜„\n",
    "- í•µì‹¬ ì •ë³´ë§Œ ë‚¨ê¸°ëŠ” ëŠë‚Œ\n",
    "\n",
    "#### 3ï¸âƒ£ ë‹¤ì‹œ ê·¸ ì‘ì€ í‘œí˜„ìœ¼ë¡œë¶€í„° ì›ë˜ ì…ë ¥ì„ ë³µì›í•œë‹¤\n",
    "- ì••ì¶•ëœ ì •ë³´ë¥¼ ì´ìš©í•´ì„œ ìµœëŒ€í•œ ì›ë˜ë‘ ë˜‘ê°™ì´ ì¶œë ¥í•˜ë ¤ê³  í•¨\n",
    "\n",
    "### ğŸ—œï¸ ì™œ ì••ì¶•í•˜ë‚˜?\n",
    "- ì¤‘ìš”í•œ íŠ¹ì§•ë§Œ ë½‘ì•„ë‚´ë ¤ê³ \n",
    "- ë…¸ì´ì¦ˆ ì œê±°, ë°ì´í„° ì••ì¶•, íŠ¹ì§• ì¶”ì¶œ ë“±ì— í™œìš©\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… AutoEncoderì˜ 4ê°€ì§€ ì£¼ìš” íŒŒíŠ¸\n",
    "\n",
    "### 1ï¸âƒ£ Encoder (ì¸ì½”ë”)\n",
    "- **ë¬´ì—‡ì„ í•˜ë‚˜ìš”?**  \n",
    "  ì›ë˜ì˜ ì…ë ¥ ë°ì´í„°ë¥¼ **ì ì  ì‘ì€ ì°¨ì›**ìœ¼ë¡œ ì••ì¶•í•©ë‹ˆë‹¤.\n",
    "- **ì˜ˆë¥¼ ë“¤ì–´ì„œ?**  \n",
    "  ê³ ì–‘ì´ ì‚¬ì§„(í° ì´ë¯¸ì§€)ì„ â†’ ì‘ì€ ë²¡í„° í˜•íƒœë¡œ ë³€í™˜\n",
    "- **ì™œ í•„ìš”í•´ìš”?**  \n",
    "  ì…ë ¥ ë°ì´í„°ì—ì„œ ì¤‘ìš”í•œ íŠ¹ì§•(í•µì‹¬ ì •ë³´)ë§Œ ì¶”ì¶œí•˜ê¸° ìœ„í•´\n",
    "\n",
    "### 2ï¸âƒ£ Bottleneck (Latent Space, ì ì¬ ê³µê°„)\n",
    "- **ë¬´ì—‡ì„ í•˜ë‚˜ìš”?**  \n",
    "  **ê°€ì¥ ì‘ì€ ì°¨ì›**ìœ¼ë¡œ ì••ì¶•ëœ ìƒíƒœ\n",
    "- **ì™œ bottleneckì´ë¼ê³  ë¶€ë¥´ë‚˜ìš”?**  \n",
    "  ë³‘ëª© ì§€ì ì²˜ëŸ¼ ë°ì´í„°ë¥¼ ê°•ì œë¡œ í†µê³¼ì‹œí‚¤ê¸° ë•Œë¬¸ì—\n",
    "- **ì—­í• ?**  \n",
    "  ë°ì´í„°ë¥¼ ìš”ì•½í•˜ëŠ” **ì ì¬ í‘œí˜„(latent representation)** ì„ ë‹´ëŠ”ë‹¤\n",
    "- **ì¤‘ìš”í•œ ì ?**  \n",
    "  ì´ ê³µê°„ì„ í†µí•´ íŠ¹ì§• ì••ì¶•, ë…¸ì´ì¦ˆ ì œê±°, ë°ì´í„° êµ¬ì¡° ì´í•´ ë“± ë‹¤ì–‘í•œ ì‘ìš© ê°€ëŠ¥\n",
    "\n",
    "### 3ï¸âƒ£ Decoder (ë””ì½”ë”)\n",
    "- **ë¬´ì—‡ì„ í•˜ë‚˜ìš”?**  \n",
    "  Bottleneckì—ì„œ ì–»ì€ ì‘ì€ ë²¡í„°ë¥¼ **ë‹¤ì‹œ ì›ë˜ ë°ì´í„°ì˜ í˜•íƒœë¡œ ë³µì›**í•©ë‹ˆë‹¤.\n",
    "- **ì˜ˆë¥¼ ë“¤ì–´ì„œ?**  \n",
    "  ì‘ì€ ë²¡í„° â†’ ì›ë˜ ê³ ì–‘ì´ ì‚¬ì§„ìœ¼ë¡œ ì¬êµ¬ì„±\n",
    "- **ì—­í• ?**  \n",
    "  ì–¼ë§ˆë‚˜ ì˜ ë³µì›í•  ìˆ˜ ìˆëŠ”ì§€ í‰ê°€í•˜ê³ , ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµì‹œí‚¨ë‹¤\n",
    "\n",
    "### 4ï¸âƒ£ Reconstruction Loss (ì¬êµ¬ì„± ì†ì‹¤)\n",
    "- **ë¬´ì—‡ì„ í•˜ë‚˜ìš”?**  \n",
    "  **ì›ë˜ ì…ë ¥ ë°ì´í„°ì™€ ë³µì›ëœ ë°ì´í„° ê°„ì˜ ì°¨ì´**ë¥¼ ê³„ì‚°\n",
    "- **ì˜ˆë¥¼ ë“¤ì–´ì„œ?**  \n",
    "  ì›ë³¸ ì´ë¯¸ì§€ì™€ ë””ì½”ë”ê°€ ë³µì›í•œ ì´ë¯¸ì§€ê°€ ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œì§€ë¥¼ ë¹„êµ\n",
    "- **ì™œ í•„ìš”í•´ìš”?**  \n",
    "  ì°¨ì´ê°€ ì‘ì„ìˆ˜ë¡, ì¦‰ **ì†ì‹¤ì´ ì‘ì„ìˆ˜ë¡** ë„¤íŠ¸ì›Œí¬ê°€ ì˜ í•™ìŠµë˜ê³  ìˆë‹¤ê³  íŒë‹¨\n",
    "- **ì–´ë–»ê²Œ ì‚¬ìš©ë˜ë‚˜ìš”?**  \n",
    "  ë„¤íŠ¸ì›Œí¬ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” í•µì‹¬ ì§€í‘œ\n",
    "\n",
    "## í•œ ì¤„ ìš”ì•½\n",
    "> Encoderê°€ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ê³ , Bottleneckì— ì €ì¥í•˜ë©°, Decoderê°€ ë³µì›í•˜ê³ , Reconstruction Lossë¡œ ë³µì› ì„±ëŠ¥ì„ í‰ê°€í•œë‹¤!\n",
    "\n",
    "- Encoderì™€ DecoderëŠ” ì—¬ëŸ¬ ê²¹(ì—¬ëŸ¬ ì¸µ)ìœ¼ë¡œ ìŒ“ì—¬ ìˆì§€ë§Œ, ì¤‘ê°„ì— ì••ì¶•ëœ Bottleneck ë¶€ë¶„(ì ì¬ ê³µê°„)ì€ ë³´í†µ í•˜ë‚˜ì˜ ì¸µë§Œ ì“´ë‹¤.\n",
    "- ì´ ì¤‘ê°„ ì¸µ(ì ì¬ ê³µê°„)ì— ëª‡ ê°œì˜ ë‰´ëŸ°ì„ ì“¸ì§€ëŠ” ì •í•´ì§„ ê³µì‹ì´ ì—†ê³ , ì‹¤í—˜ì„ í†µí•´ (ì˜ˆë¥¼ ë“¤ì–´ reconstruction lossë‚˜ downstream task ì„±ëŠ¥ì„ ë³´ë©´ì„œ) ì°¾ì•„ì•¼ í•œë‹¤ëŠ” ëœ»ì´ë‹¤.\n",
    "\n",
    "## ğŸ“„ Autoencoder ì¢…ë¥˜ì™€ ì„¤ëª…\n",
    "### âœ¨ ê³µí†µ: BackPropagation to minimize reconstruction loss\n",
    "- AutoencoderëŠ” **ì…ë ¥ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ê³  ë‹¤ì‹œ ë³µì›**í•˜ë©´ì„œ, ë³µì›ëœ ì¶œë ¥ê³¼ ì›ë˜ ì…ë ¥ì˜ ì°¨ì´ë¥¼ ìµœì†Œí™”í•˜ëŠ” **reconstruction loss**ë¥¼ ì¤„ì´ë„ë¡ **BackPropagation (ì—­ì „íŒŒ)**ì„ ì‚¬ìš©í•œë‹¤.\n",
    "\n",
    "### ğŸ”¹ Vanilla Autoencoder\n",
    "- **êµ¬ì¡°**: ê°€ì¥ ê¸°ë³¸ì ì¸ í˜•íƒœ. Encoderì™€ Decoderê°€ ê°ê° ì™„ì „ ì—°ê²°ì¸µ (Fully connected layer)ìœ¼ë¡œë§Œ ì´ë£¨ì–´ì ¸ ìˆìŒ.\n",
    "- **ëª©ì **: ë‹¨ìˆœíˆ ë°ì´í„° ì••ì¶•ê³¼ ë³µì›.\n",
    "- **í•œê³„**: ë³µì¡í•œ íŒ¨í„´ì´ë‚˜ ì´ë¯¸ì§€ ê°™ì€ ê³µê°„ ì •ë³´ë¥¼ ì˜ í‘œí˜„í•˜ê¸° ì–´ë ¤ì›€.\n",
    "\n",
    "### ğŸ”¹ Multilayer Autoencoder\n",
    "- **êµ¬ì¡°**: Encoderì™€ Decoderì— ì—¬ëŸ¬ ì¸µ(Deep structure)ì„ ì¶”ê°€.\n",
    "- **ì¥ì **: ë” ë³µì¡í•œ ë¹„ì„ í˜• ë³€í™˜ì„ í•™ìŠµí•  ìˆ˜ ìˆìŒ.\n",
    "- **í™œìš©**: ê¸°ë³¸ autoencoderë³´ë‹¤ ë” ì •êµí•œ íŠ¹ì§• ì¶”ì¶œì— ì‚¬ìš©.\n",
    "\n",
    "### ğŸ”¹ Convolutional Autoencoder\n",
    "- **êµ¬ì¡°**: Encoderì™€ Decoderì— Convolution layer(í•©ì„±ê³± ì¸µ) ì‚¬ìš©.\n",
    "- **ì¥ì **: ì´ë¯¸ì§€ë‚˜ ì‹œê°ì  ë°ì´í„°ì˜ **ê³µê°„ì (local) íŒ¨í„´**ì„ ì˜ ë³´ì¡´.\n",
    "- **í™œìš©**: ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ì œê±°, ì´ë¯¸ì§€ ì••ì¶• ë“±.\n",
    "\n",
    "### ğŸ”¹ Regularized Autoencoder\n",
    "#### â–ª Sparse Autoencoder\n",
    "- **êµ¬ì¡°**: ìˆ¨ì€ ì¸µì˜ í™œì„±í™”(activation)ì— sparsity constraint(í¬ì†Œì„± ì œì•½)ë¥¼ ì¶”ê°€.\n",
    "- **ì¥ì **: ì¤‘ìš”í•œ íŠ¹ì§•ë§Œ í‘œí˜„í•˜ë„ë¡ ìœ ë„ â†’ feature selection íš¨ê³¼.\n",
    "\n",
    "#### â–ª Denoising Autoencoder\n",
    "- **êµ¬ì¡°**: ì…ë ¥ ë°ì´í„°ì— ì¼ë¶€ëŸ¬ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€í•˜ê³ , ê¹¨ë—í•œ ì›ë³¸ì„ ë³µì›í•˜ë„ë¡ í•™ìŠµ.\n",
    "- **ì¥ì **: ë” ê²¬ê³ í•˜ê³  ì¼ë°˜í™”ëœ í‘œí˜„(robust representation)ì„ í•™ìŠµ.\n",
    "\n",
    "### ğŸ”¹ Recurrent Autoencoder\n",
    "- **êµ¬ì¡°**: Encoderì™€ Decoderì— RNN(LSTM, GRU ë“±)ì„ ì‚¬ìš©.\n",
    "- **ì¥ì **: ìˆœì°¨ ë°ì´í„°(Sequence data) ì²˜ë¦¬ê°€ ê°€ëŠ¥.\n",
    "- **í™œìš©**:\n",
    "  - **ë¹„ë””ì˜¤**: í”„ë ˆì„ ìˆœì„œ ë³´ì¡´í•˜ë©´ì„œ ì••ì¶•.\n",
    "  - **ì‹œê³„ì—´(Time series)**: ì‹œê³„ì—´ ì´ìƒ íƒì§€, ì˜ˆì¸¡ ë“±.\n",
    "\n",
    "## âœ… ìš”ì•½\n",
    "\n",
    "| ì¢…ë¥˜              | íŠ¹ì§•                           | ì£¼ìš” í™œìš© ì˜ˆì‹œ                |\n",
    "|-----------------|-----------------------------|---------------------------|\n",
    "| Vanilla        | ê¸°ë³¸ êµ¬ì¡°                    | ë‹¨ìˆœ ì••ì¶•, ì‹œê°í™”       |\n",
    "| Multilayer     | ë” ê¹Šì€ êµ¬ì¡°              | ë³µì¡í•œ ë°ì´í„° í‘œí˜„   |\n",
    "| Convolutional | í•©ì„±ê³± ì¸µ ì‚¬ìš©          | ì´ë¯¸ì§€, ë¹„ì£¼ì–¼ ë°ì´í„° |\n",
    "| Regularized   | ì œì•½ ì¡°ê±´ ì¶”ê°€          | í¬ì†Œ í‘œí˜„, ë…¸ì´ì¦ˆ ì œê±° |\n",
    "| Recurrent    | ìˆœì°¨ì  êµ¬ì¡°              | ì˜ìƒ, ì‹œê³„ì—´ ë¶„ì„      |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“„ Autoencoder ì¶”ê°€ ê°œë… ì •ë¦¬\n",
    "### ğŸ”¥ Types: Undercomplete vs Overcomplete\n",
    "#### â–ª Undercomplete Autoencoder\n",
    "- **ì •ì˜**: ì ì¬ ê³µê°„(latent space)ì˜ ì°¨ì›ì´ **ì…ë ¥ ì°¨ì›ë³´ë‹¤ ì‘ì€** ê²½ìš°.\n",
    "- **ëª©ì **: ë°ì´í„°ë¥¼ ì••ì¶•(ì°¨ì› ì¶•ì†Œ)í•˜ë©´ì„œ í•µì‹¬ì ì¸ íŠ¹ì§•ë§Œ ì¶”ì¶œ.\n",
    "- **ì¥ì **: ê³¼ì í•©(overfitting)ì„ ë°©ì§€í•˜ê³ , ì¡ìŒì„ ì¤„ì´ë©° ì¤‘ìš”í•œ ì •ë³´ë§Œ ë‚¨ê¹€.\n",
    "- **ì˜ˆì‹œ**: ì´ë¯¸ì§€ë‚˜ ë°ì´í„°ì˜ ì£¼ìš” êµ¬ì¡°ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ë²„ë¦¬ëŠ” ê²½ìš°.\n",
    "\n",
    "#### â–ª Overcomplete Autoencoder\n",
    "- **ì •ì˜**: ì ì¬ ê³µê°„ì˜ ì°¨ì›ì´ **ì…ë ¥ ì°¨ì›ë³´ë‹¤ í°** ê²½ìš°.\n",
    "- **ëª©ì **: ë” í’ë¶€í•˜ê³  ë‹¤ì–‘í•œ í‘œí˜„ í•™ìŠµ.\n",
    "- **ìœ„í—˜**: ë‹¨ìˆœíˆ ì…ë ¥ì„ ë³µì‚¬í•˜ê²Œ ë˜ì–´ ë¬´ì˜ë¯¸í•œ í•™ìŠµì´ ë  ìˆ˜ ìˆìŒ â†’ ê·œì œ(regularization)ê°€ í•„ìš” (ì˜ˆ: sparsity, noise ë“±).\n",
    "- **í™œìš©**: ë³µì¡í•œ íŒ¨í„´ì´ë‚˜ ê³ ì°¨ì› ë°ì´í„°ì—ì„œ í’ë¶€í•œ featureë¥¼ ë½‘ì•„ë‚´ê³  ì‹¶ì„ ë•Œ.\n",
    "\n",
    "### ğŸ’¡ Autoencoder êµ¬í˜„ ë°©ì‹\n",
    "#### â–ª Feedforward Autoencoder (MLP ê¸°ë°˜)\n",
    "- **êµ¬ì„±**: ì™„ì „ ì—°ê²°ì¸µ(fully connected layer)ì„ ì´ìš©í•œ ë‹¤ì¸µ í¼ì…‰íŠ¸ë¡  (MLP).\n",
    "- **í™œìš©**: ì¼ë°˜ì ì¸ tabular data, ê°„ë‹¨í•œ ì´ë¯¸ì§€ (flattenëœ ë²¡í„°).\n",
    "\n",
    "#### â–ª LSTM Autoencoder\n",
    "- **êµ¬ì„±**: LSTM (Long Short-Term Memory) ë˜ëŠ” ë‹¤ë¥¸ RNN ê¸°ë°˜ layer ì‚¬ìš©.\n",
    "- **í™œìš©**: ì‹œê³„ì—´ ë°ì´í„°, ìì—°ì–´, ë¹„ë””ì˜¤ ë“± **ìˆœì°¨ ë°ì´í„°**.\n",
    "- **íŠ¹ì§•**: ì‹œì  ê°„ì˜ ì˜ì¡´ì„±(temporal dependency)ì„ í•™ìŠµí•  ìˆ˜ ìˆìŒ.\n",
    "\n",
    "#### â–ª CNN Autoencoder\n",
    "- **êµ¬ì„±**: í•©ì„±ê³±(Convolution) layerë¥¼ Encoder/Decoderì— ì‚¬ìš©.\n",
    "- **í™œìš©**: ì´ë¯¸ì§€, ìŒì„±, 2D íŒ¨í„´ ë“± ê³µê°„ì  ì •ë³´ë¥¼ ë³´ì¡´í•´ì•¼ í•  ë•Œ.\n",
    "- **íŠ¹ì§•**: êµ­ì†Œì (local) íŠ¹ì§• ì¶”ì¶œì— ê°•í•¨.\n",
    "\n",
    "### âš¡ Autoencoder without non-linearity â‰ˆ PCA\n",
    "- **ì„¤ëª…**:\n",
    "  - Autoencoderì—ì„œ **activation function (ì˜ˆ: ReLU, sigmoid, tanh ë“±)**ì„ ì œê±°í•˜ë©´, Encoderì™€ Decoderê°€ **ì„ í˜•(linear) ë³€í™˜**ë§Œ ìˆ˜í–‰.\n",
    "  - ì´ ê²½ìš°, AutoencoderëŠ” **ì…ë ¥ ë°ì´í„°ë¥¼ ì„ í˜•ì ìœ¼ë¡œ ì••ì¶•**í•˜ëŠ”ë°, ì´ëŠ” **PCA (Principal Component Analysis)**ì™€ ë³¸ì§ˆì ìœ¼ë¡œ ê°™ìŒ.\n",
    "- **ì¦‰**:\n",
    "  - linear autoencoder = PCA\n",
    "  - **PCA**ëŠ” ë°ì´í„°ì˜ ë¶„ì‚°ì„ ìµœëŒ€í™”í•˜ëŠ” ì¶•ì„ ì°¾ì•„ ë°ì´í„° ì°¨ì›ì„ ì¶•ì†Œí•¨.  \n",
    "  - **Autoencoder**ëŠ” reconstruction errorë¥¼ ìµœì†Œí™”í•˜ë„ë¡ í•™ìŠµí•˜ì§€ë§Œ, activation ì—†ì´ ì„ í˜• ë³€í™˜ë§Œ ì“°ë©´ ê²°êµ­ ê°™ì€ ê²°ê³¼ë¥¼ ëƒ„.\n",
    "\n",
    "Autoencoder types : (not limited to â€¦ )\n",
    "https://towardsdatascience.com/deep-inside-autoencoders-7e41f319999f\n",
    "https://towardsdatascience.com/auto-encoder-what-is-it-and-what-is-it-used-for-part-1-3e5c6f017726\n",
    "ì½”ë“œ ì‹¤í–‰í•´ë³¼ê²ƒ.\n",
    "\n",
    "ì•„ë˜ í˜ì´ì§€ì— ëŒ€í•œ í•´ì„\n",
    "Adding a sparsity constraint on the encoded representations.\n",
    "In Keras, this can be done by adding an activity_regularizer to our Dense layer.\n",
    "Fewer units would \"fire\" at a given time.\n",
    "```python\n",
    "encoded = layers.Dense(encoding_dim, activation='relu',\n",
    "activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "```\n",
    "With the added regularization the model is less likely to overfit and can be trained with more epoch number.\n",
    "  \n",
    "## ğŸ§¬ Adding a Sparsity Constraint on Encoded Representations\n",
    "### ğŸ’¡ ê°œë…\n",
    "- **Sparsity constraint**ëŠ” ì ì¬ ê³µê°„(latent space)ì— í¬ì†Œì„± ì œì•½ì„ ê±¸ì–´, **ì†Œìˆ˜ì˜ ë‰´ëŸ°ë§Œ í™œì„±í™”**ë˜ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.\n",
    "- ì´ë ‡ê²Œ í•˜ë©´ ëª¨ë¸ì´ **ë” ê°„ê²°í•œ feature í‘œí˜„**ì„ í•™ìŠµí•˜ê³ , **ê³¼ì í•©(overfitting)**ì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### âš¡ Kerasì—ì„œ ì ìš© ë°©ë²•\n",
    "```python\n",
    "from keras import layers, regularizers\n",
    "\n",
    "encoded = layers.Dense(\n",
    "    encoding_dim,\n",
    "    activation='relu',\n",
    "    activity_regularizer=regularizers.l1(10e-5)\n",
    ")(input_img)\n",
    "```\n",
    "- activity_regularizer: layerì˜ ì¶œë ¥(activation)ì— ëŒ€í•œ ì •ê·œí™” ê·œì œ ì¶”ê°€.\n",
    "- regularizers.l1(10e-5): L1 penaltyë¥¼ ì¶”ê°€í•´ ë‰´ëŸ°ì´ 0ì— ê°€ê¹Œì›Œì§€ë„ë¡ ìœ ë„ â†’ í¬ì†Œì„± ì¦ê°€.\n",
    "  \n",
    "### íš¨ê³¼\n",
    "- ì†Œìˆ˜ì˜ ë‰´ëŸ°ë§Œ \"fire\" â†’ ë‚˜ë¨¸ì§€ëŠ” 0ì— ê°€ê¹Œì›€.\n",
    "- ëª¨ë¸ì˜ ë³µì¡ì„±ì„ ì¤„ì´ê³ , ì¼ë°˜í™” ì„±ëŠ¥ì„ í–¥ìƒ.\n",
    "- ê³¼ì í•© ìœ„í—˜ ê°ì†Œ â†’ ë” ë§ì€ epoch ë™ì•ˆ ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµ ê°€ëŠ¥.\n",
    "\n",
    "## LSTM ê¸°ë°˜ Autoencoder ì„¤ëª…\n",
    "### 1ï¸âƒ£ ì…ë ¥ì€ ì‹œí€€ìŠ¤ (sequence)\n",
    "- ë°ì´í„°ê°€ ì‹œê°„ì— ë”°ë¼ ë‚˜ì—´ëœ ì—°ì†ëœ ê°’ë“¤ (ì˜ˆ: ì‹œê³„ì—´, ë¬¸ì¥, ìŒì„± ë“±)\n",
    "- ì˜ˆ: `[x1, x2, x3, ..., xT]`\n",
    "\n",
    "### 2ï¸âƒ£ LSTM Encoder\n",
    "- ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ë°›ì•„ì„œ **ì „ì²´ ì‹œí€€ìŠ¤ ì •ë³´ë¥¼ ë‹´ì€ í•˜ë‚˜ì˜ ë²¡í„°(ì»¨í…ìŠ¤íŠ¸ ë²¡í„°)**ë¡œ ë³€í™˜\n",
    "- ì¦‰, Tê°œì˜ ì‹œì (time-step)ì„ ê±°ì³ ë§ˆì§€ë§‰ì— **ê³ ì • ê¸¸ì´ ë²¡í„°** ìƒì„±\n",
    "\n",
    "### 3ï¸âƒ£ ë²¡í„° ë°˜ë³µ (Repeat Vector)\n",
    "- ì´ ê³ ì • ê¸¸ì´ ë²¡í„°ë¥¼ ë””ì½”ë”ì˜ ì…ë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´(n)ë§Œí¼ **ë³µì œ(repeat)**\n",
    "- ì˜ˆ: ê³ ì • ë²¡í„° â†’ `[v, v, v, ..., v]` (ê¸¸ì´ n)\n",
    "\n",
    "### 4ï¸âƒ£ LSTM Decoder\n",
    "- ë°˜ë³µëœ ë²¡í„° ì‹œí€€ìŠ¤ë¥¼ ë°›ì•„, ì´ë¥¼ ë‹¤ì‹œ ì›ë˜ ì‹œí€€ìŠ¤ ë˜ëŠ” ëª©í‘œ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜\n",
    "- ì¦‰, **ê³ ì • ë²¡í„° â†’ ì¶œë ¥ ì‹œí€€ìŠ¤ ë³µì›**\n",
    "\n",
    "### ìš”ì•½\n",
    "| ë‹¨ê³„           | ì—­í•                                         |\n",
    "|--------------|-------------------------------------------|\n",
    "| ì…ë ¥           | ì‹œê°„ì— ë”°ë¥¸ ìˆœì„œê°€ ìˆëŠ” ì‹œí€€ìŠ¤ ë°ì´í„°                      |\n",
    "| LSTM Encoder | ì‹œí€€ìŠ¤ â†’ ê³ ì • ê¸¸ì´ ë²¡í„° (ì „ì²´ ì •ë³´ ì••ì¶•)               |\n",
    "| Repeat Vector | ê³ ì • ë²¡í„°ë¥¼ ì¶œë ¥ ì‹œí€€ìŠ¤ ê¸¸ì´ë§Œí¼ ë°˜ë³µ                        |\n",
    "| LSTM Decoder | ë°˜ë³µëœ ë²¡í„° â†’ ì›ë˜ ì‹œí€€ìŠ¤ ë˜ëŠ” ë³µì›ëœ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜          |\n",
    "\n",
    "### í•œë§ˆë”” ì •ë¦¬\n",
    "\n",
    "> LSTM AutoencoderëŠ” ì‹œí€€ìŠ¤ ë°ì´í„°ë¥¼ í•œ ë²¡í„°ë¡œ ì••ì¶•í–ˆë‹¤ê°€, ê·¸ ë²¡í„°ë¥¼ ë°˜ë³µí•´ì„œ ë‹¤ì‹œ ì‹œí€€ìŠ¤ë¡œ ë³µì›í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "----\n",
    "A Gentle Introduction to LSTM Autoencoders\n",
    "https://machinelearningmastery.com/lstm-autoencoders/\n",
    "  \n",
    "ìœ„ì— url ë‚´ìš© ìš”ì•½\n",
    "## LSTM Autoencoders â€“ Machine Learning Mastery ê¸€ ìš”ì•½\n",
    "### 1. LSTM Autoencoderë€?\n",
    "- **Autoencoder**ëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ê³  ë‹¤ì‹œ ë³µì›í•˜ëŠ” ì‹ ê²½ë§.\n",
    "- LSTM AutoencoderëŠ” **ìˆœì°¨ì  ì‹œê³„ì—´ ë°ì´í„°**ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•´ LSTM(Recurrent Neural Network)ì„ í™œìš©.\n",
    "\n",
    "### 2. LSTM Autoencoder êµ¬ì¡°\n",
    "- **Encoder**: ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ë°›ì•„ ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ ì€ë‹‰ ìƒíƒœ(hidden state)ë¥¼ ìƒì„±. ì´ ë²¡í„°ëŠ” ì‹œí€€ìŠ¤ ì „ì²´ì˜ ìš”ì•½ ì •ë³´ë¥¼ ë‹´ìŒ.\n",
    "- **Decoder**: ì´ ê³ ì • ê¸¸ì´ ë²¡í„°ë¥¼ ì´ˆê¸° ìƒíƒœë¡œ ì‚¬ìš©í•´, ì›ë˜ ì‹œí€€ìŠ¤ë¥¼ ì¬êµ¬ì„±í•˜ê±°ë‚˜ ì¶œë ¥ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±.\n",
    "\n",
    "### 3. ì™œ LSTM Autoencoderë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€?\n",
    "- ì‹œê³„ì—´ ë°ì´í„°, í…ìŠ¤íŠ¸, ìŒì„±, ë™ì˜ìƒ ë“± **ìˆœì°¨ ë°ì´í„°**ì— íš¨ê³¼ì .\n",
    "- ë¹„ì§€ë„í•™ìŠµ(unsupervised learning) ë°©ì‹ìœ¼ë¡œ **íŠ¹ì§• ì¶”ì¶œ(feature extraction)** ê°€ëŠ¥.\n",
    "- **ì´ìƒ íƒì§€(anomaly detection)**ì—ë„ í™œìš© ê°€ëŠ¥ (ì¬êµ¬ì„± ì˜¤ë¥˜ ê¸°ë°˜).\n",
    "\n",
    "### 4. LSTM Autoencoder êµ¬í˜„ ì£¼ìš” í¬ì¸íŠ¸\n",
    "- ì…ë ¥ ì‹œí€€ìŠ¤ í¬ê¸°(shape)ë¥¼ ëª…í™•íˆ ì§€ì •í•´ì•¼ í•¨.\n",
    "- EncoderëŠ” ì‹œí€€ìŠ¤ë¥¼ í•˜ë‚˜ì˜ ê³ ì • ë²¡í„°ë¡œ ì••ì¶•.\n",
    "- DecoderëŠ” ì´ ë²¡í„°ë¥¼ ë°˜ë³µ(repeat)í•˜ì—¬ ì‹œí€€ìŠ¤ë¡œ ë³µì›.\n",
    "\n",
    "### 5. ê°„ë‹¨í•œ ì˜ˆì œ ì½”ë“œ (Keras)\n",
    "- LSTM layersë¥¼ í™œìš©í•´ encoder-decoder êµ¬ì¡° êµ¬ì„±.\n",
    "- RepeatVector, TimeDistributed(Dense) ë ˆì´ì–´ ì‚¬ìš©.\n",
    "\n",
    "### 6. í™œìš© ì‚¬ë¡€\n",
    "- ì´ìƒ íƒì§€: ì •ìƒ ë°ì´í„° í•™ìŠµ í›„ ì¬êµ¬ì„± ì˜¤ë¥˜ë¥¼ í†µí•´ ë¹„ì •ìƒ ì—¬ë¶€ íŒë‹¨.\n",
    "- ì‹œê³„ì—´ ë°ì´í„° ì••ì¶• ë° ë³µì›.\n",
    "- íŠ¹ì§• ë²¡í„° ì¶”ì¶œ í›„ ë‹¤ë¥¸ ëª¨ë¸ì— í™œìš©.\n",
    "\n",
    "### ìš”ì•½\n",
    "| í•­ëª©                 | ì„¤ëª…                                    |\n",
    "|--------------------|---------------------------------------|\n",
    "| ëª©ì                  | ì‹œê³„ì—´ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì••ì¶•, ë³µì›            |\n",
    "| êµ¬ì¡°                 | LSTM encoder + ê³ ì • ë²¡í„° + LSTM decoder       |\n",
    "| ì£¼ìš” í™œìš©             | ì´ìƒ íƒì§€, íŠ¹ì§• ì¶”ì¶œ, ì‹œê³„ì—´ ë°ì´í„° ì••ì¶•          |\n",
    "| ì¥ì                  | ìˆœì°¨ ì •ë³´ ìœ ì§€, ë¹„ì§€ë„í•™ìŠµ ê°€ëŠ¥                   |\n",
    "\n",
    "---\n",
    "Loss Function in AutoEncoder\n",
    "â€œDenoising autoencoders (DAEs) consist of an encoder and decoder which may be trained simultaneously to minimise a loss (function) between an input and the reconstruction of a corrupted version of the input. There are two common loss functions used for training autoencoders, these include the mean-squared error (MSE) and the binary cross-entropy (BCE).\"\n",
    "Scale between 0 and 1 ---- > BCE is highly recommended ( image processing )\n",
    "\n",
    "https://arxiv.org/pdf/1708.08487.pdf\n",
    "\n",
    "--- \n",
    "## Autoencoder with tied weights\n",
    "### ğŸ’¡ ê°œë…\n",
    "- **Tied weights**ëŠ” encoderì™€ decoderê°€ **ë™ì¼í•œ ê°€ì¤‘ì¹˜ë¥¼ ê³µìœ **í•˜ë„ë¡ í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.\n",
    "- decoderì˜ ê°€ì¤‘ì¹˜ëŠ” encoder ê°€ì¤‘ì¹˜ì˜ **ì „ì¹˜(transpose)** í˜•íƒœë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸŸ¢ Form of parameter sharing\n",
    "- encoderì™€ decoderê°€ ê°™ì€ weight setì„ ê³µìœ .\n",
    "- ì¼ë°˜ì ì¸ autoencoderëŠ” encoderì™€ decoder ê°ê° ë³„ë„ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, tied weightsë¥¼ ì‚¬ìš©í•˜ë©´ **íŒŒë¼ë¯¸í„° ìˆ˜ê°€ í¬ê²Œ ì¤„ì–´ë“¦**.\n",
    "\n",
    "### ğŸ” Decoder weights are the transpose of the encoder weights\n",
    "- ì˜ˆë¥¼ ë“¤ì–´, encoder weightê°€ \\( W \\)ë¼ë©´, decoder weightëŠ” \\( W^T \\).\n",
    "- decoderëŠ” encoderì˜ \"ì—­ë°©í–¥\" ì—­í• .\n",
    "\n",
    "### âš¡ íš¨ê³¼\n",
    "#### ğŸ“‰ íŒŒë¼ë¯¸í„° ìˆ˜ ê°ì†Œ\n",
    "- ëª¨ë¸ì˜ ë³µì¡ì„±ì„ ì¤„ì´ê³ , **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ ì €ì¥ ê³µê°„** ì ˆì•½.\n",
    " \n",
    "#### ğŸš€ Speed\n",
    "- íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì¤„ì–´ ê³„ì‚° ì†ë„ê°€ **ë” ë¹¨ë¼ì§**.\n",
    "\n",
    "#### ğŸ™…â€â™‚ï¸ Overfitting ë°©ì§€\n",
    "- ë¶ˆí•„ìš”í•œ íŒŒë¼ë¯¸í„°ê°€ ì¤„ì–´ë“¤ì–´ **ê³¼ì í•© ë°©ì§€** íš¨ê³¼.\n",
    "\n",
    "### âœ… í•œ ì¤„ ìš”ì•½\n",
    "> **\"Tied weightsëŠ” encoderì™€ decoderê°€ ë™ì¼í•œ ê°€ì¤‘ì¹˜ë¥¼ ê³µìœ í•˜ë„ë¡ í•˜ì—¬ íŒŒë¼ë¯¸í„°ë¥¼ ì¤„ì´ê³ , ì†ë„ë¥¼ ë†’ì´ë©°, ê³¼ì í•©ì„ ë°©ì§€í•˜ëŠ” ê¸°ë²•ì´ë‹¤.\"**\n",
    "\n",
    "### ğŸŸ¢ ìš”ì•½ í‘œ\n",
    "| í•­ëª©                   | ì„¤ëª…                                    |\n",
    "|----------------------|---------------------------------------|\n",
    "| ê°œë…                  | encoder & decoder weight ê³µìœ         |\n",
    "| decoder weight í˜•íƒœ | encoder weightì˜ ì „ì¹˜(transpose)    |\n",
    "| ì¥ì                   | íŒŒë¼ë¯¸í„° ìˆ˜ ê°ì†Œ, ì†ë„ ì¦ê°€, ê³¼ì í•© ë°©ì§€ |\n",
    "\n",
    "---\n",
    "\n",
    "## Variational Autoencoder (VAE) ì„¤ëª…\n",
    "### ğŸ’¡ ê°œë…\n",
    "- **Variational Autoencoder**ëŠ” **í™•ë¥ ì  ìƒì„± ëª¨ë¸(Probabilistic Generative Model)**ì…ë‹ˆë‹¤.\n",
    "- ì¼ë°˜ì ì¸ AutoencoderëŠ” ë‹¨ìˆœíˆ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ê³  ë³µì›í•˜ëŠ” ë° ì´ˆì ì„ ë‘ì§€ë§Œ, VAEëŠ” **ë°ì´í„°ì˜ ë¶„í¬ë¥¼ í•™ìŠµ**í•˜ì—¬ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸŸ¢ í•µì‹¬ ì•„ì´ë””ì–´\n",
    "- **ì ì¬ ê³µê°„(latent space)**ì— í™•ë¥  ë¶„í¬(ì£¼ë¡œ ì •ê·œë¶„í¬)ë¥¼ ê°€ì •.\n",
    "- EncoderëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ **ë¶„í¬ì˜ í‰ê· (Î¼)ê³¼ í‘œì¤€í¸ì°¨(Ïƒ)**ë¡œ ë§¤í•‘.\n",
    "- DecoderëŠ” ì´ ë¶„í¬ì—ì„œ ìƒ˜í”Œë§ëœ ê°’ì„ ì‚¬ìš©í•´ ë°ì´í„°ë¥¼ ìƒì„±.\n",
    "\n",
    "### ğŸ”¥ ì£¼ìš” êµ¬ì„±\n",
    "#### 1ï¸âƒ£ Encoder\n",
    "- ì…ë ¥ $x$ë¥¼ ë°›ì•„ ì ì¬ ê³µê°„ì˜ **í‰ê·  ë²¡í„° $\\mu$** ì™€ **í‘œì¤€í¸ì°¨ ë²¡í„° $\\sigma$** ë¥¼ ì¶œë ¥.\n",
    "\n",
    "#### 2ï¸âƒ£ Reparameterization Trick\n",
    "- $ z = \\mu + \\sigma \\times \\epsilon $\n",
    "- $\\epsilon$ì€ í‘œì¤€ ì •ê·œë¶„í¬ì—ì„œ ìƒ˜í”Œë§ëœ noise.\n",
    "- ì´ íŠ¸ë¦­ ë•ë¶„ì— ì—­ì „íŒŒ(backpropagation)ê°€ ê°€ëŠ¥.\n",
    "\n",
    "#### 3ï¸âƒ£ Decoder\n",
    "- ìƒ˜í”Œë§ëœ $z$ë¥¼ ì´ìš©í•´ ì…ë ¥ ë°ì´í„° $ x $ë¥¼ ë³µì›.\n",
    "\n",
    "### âš–ï¸ ì†ì‹¤ í•¨ìˆ˜\n",
    "#### âœ… ì¬êµ¬ì„± ì†ì‹¤ (Reconstruction Loss)\n",
    "- ì›ë˜ ë°ì´í„°ì™€ ë³µì›ëœ ë°ì´í„° ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ìµœì†Œí™”.\n",
    "\n",
    "#### âœ… KL Divergence Loss\n",
    "- ì ì¬ ë³€ìˆ˜ ë¶„í¬ $q(z|x)$ê°€ í‘œì¤€ ì •ê·œë¶„í¬ $ p(z) $ì™€ ë¹„ìŠ·í•˜ë„ë¡ ìœ ë„.\n",
    "- ìµœì¢… ì†ì‹¤:\n",
    "$\n",
    "\\mathcal{L} = \\text{Reconstruction Loss} + D_{KL}\\bigl(q(z|x)\\|p(z)\\bigr)\n",
    "$\n",
    "\n",
    "### ğŸš€ ì¥ì \n",
    "- **ë°ì´í„° ìƒì„± ëŠ¥ë ¥**: ìƒˆë¡œìš´ ìƒ˜í”Œ ìƒì„± ê°€ëŠ¥ (ì˜ˆ: ì–¼êµ´, ê¸€ì ë“±).\n",
    "- **ì—°ì†ì ì¸ ì ì¬ ê³µê°„**: ë²¡í„° ì—°ì‚°ì´ë‚˜ interpolation(ë³´ê°„)ì´ ê°€ëŠ¥.\n",
    "\n",
    "### âš ï¸ ë‹¨ì \n",
    "- ë³µì¡í•œ ë°ì´í„° ë¶„í¬ë¥¼ ì™„ë²½í•˜ê²Œ ëª¨ë¸ë§í•˜ê¸° ì–´ë ¤ì›€.\n",
    "- ìƒì„±ëœ ìƒ˜í”Œì˜ í’ˆì§ˆì´ GANë³´ë‹¤ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ.\n",
    "\n",
    "### âœ… í•œ ì¤„ ìš”ì•½\n",
    "\n",
    "> **\"VAEëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ í™•ë¥  ë¶„í¬ë¡œ ì¸ì½”ë”©í•˜ê³ , ì´ ë¶„í¬ì—ì„œ ìƒ˜í”Œë§í•´ ë°ì´í„°ë¥¼ ì¬êµ¬ì„± ë° ìƒì„±í•  ìˆ˜ ìˆëŠ” Autoencoder ê¸°ë°˜ ìƒì„± ëª¨ë¸ì´ë‹¤.\"**\n",
    "\n",
    "### ğŸŸ¢ ìš”ì•½ í‘œ\n",
    "\n",
    "| í•­ëª©                | ì„¤ëª…                                             |\n",
    "|-------------------|------------------------------------------------|\n",
    "| í•µì‹¬ ê°œë…          | í™•ë¥ ì  ì ì¬ ê³µê°„, ë°ì´í„° ë¶„í¬ í•™ìŠµ                  |\n",
    "| Encoder ì¶œë ¥    | í‰ê· (Î¼), í‘œì¤€í¸ì°¨(Ïƒ)                           |\n",
    "| ìƒ˜í”Œë§ ê¸°ë²•     | Reparameterization Trick ì‚¬ìš©                |\n",
    "| ì†ì‹¤ í•¨ìˆ˜         | Reconstruction Loss + KL Divergence        |\n",
    "| ì¥ì               | ë°ì´í„° ìƒì„± ê°€ëŠ¥, ì—°ì†ì  latent space       |\n",
    "| ë‹¨ì               | ìƒ˜í”Œ í’ˆì§ˆ ì œí•œ, ë³µì¡í•œ ë¶„í¬ í•™ìŠµ í•œê³„            |\n",
    "\n",
    "---\n",
    "## Generative Adversarial Networks (GANs) ì„¤ëª…\n",
    "### ğŸ’¡ ê°œë…\n",
    "- **GANs**ëŠ” **ìƒì„± ëª¨ë¸(Generative Model)**ì˜ í•œ ì¢…ë¥˜ë¡œ, ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë„ë¡ í›ˆë ¨ë©ë‹ˆë‹¤.\n",
    "- 2014ë…„ Ian Goodfellowê°€ ì²˜ìŒ ì œì•ˆ.\n",
    "\n",
    "### âš”ï¸ í•µì‹¬ ì•„ì´ë””ì–´: ë‘ ë„¤íŠ¸ì›Œí¬ì˜ ê²½ìŸ\n",
    "- **Generator (ìƒì„±ì)**:\n",
    "  - ë¬´ì‘ìœ„ ë…¸ì´ì¦ˆ(z)ë¥¼ ì…ë ¥ë°›ì•„, **ì§„ì§œ ê°™ì€(fake but realistic) ë°ì´í„°**ë¥¼ ìƒì„±.\n",
    "- **Discriminator (íŒë³„ì)**:\n",
    "  - ì§„ì§œ ë°ì´í„°ì™€ Generatorê°€ ë§Œë“  ê°€ì§œ ë°ì´í„°ë¥¼ êµ¬ë³„í•˜ë ¤ê³  ì‹œë„.\n",
    "\n",
    "> **GeneratorëŠ” íŒë³„ìë¥¼ ì†ì´ë ¤ê³  í•˜ê³ , íŒë³„ìëŠ” ì´ë¥¼ ì¡ì•„ë‚´ë ¤ê³  í•¨ â†’ ì„œë¡œ ê²½ìŸí•˜ë©° ë°œì „!**\n",
    "\n",
    "### ğŸŒ€ í•™ìŠµ ê³¼ì •\n",
    "1ï¸âƒ£ GeneratorëŠ” ëœë¤ ë…¸ì´ì¦ˆë¥¼ ë°›ì•„ **ê°€ì§œ ìƒ˜í”Œ** ìƒì„±.  \n",
    "2ï¸âƒ£ DiscriminatorëŠ” **ì§„ì§œ ìƒ˜í”Œ**ê³¼ **ê°€ì§œ ìƒ˜í”Œ**ì„ ì…ë ¥ë°›ì•„ ì§„ì§œ/ê°€ì§œ ì—¬ë¶€ë¥¼ íŒë³„.  \n",
    "3ï¸âƒ£ GeneratorëŠ” Discriminatorë¥¼ ì†ì´ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµ.  \n",
    "4ï¸âƒ£ DiscriminatorëŠ” ë” ì •í™•íˆ íŒë³„í•˜ë„ë¡ í•™ìŠµ.  \n",
    "5ï¸âƒ£ ë‘ ë„¤íŠ¸ì›Œí¬ê°€ ë™ì‹œì— í•™ìŠµí•˜ë©´ì„œ ì„œë¡œ ë°œì „ â†’ GeneratorëŠ” ì ì  ë” ì§„ì§œ ê°™ì€ ë°ì´í„°ë¥¼ ìƒì„±.\n",
    "\n",
    "### âš–ï¸ ì†ì‹¤ í•¨ìˆ˜\n",
    "#### âœ… Discriminatorì˜ ëª©ì \n",
    "- ì§„ì§œ ìƒ˜í”Œì€ 1, ê°€ì§œ ìƒ˜í”Œì€ 0ìœ¼ë¡œ íŒë³„í•˜ë„ë¡ í•™ìŠµ.\n",
    "\n",
    "#### âœ… Generatorì˜ ëª©ì \n",
    "- ìƒì„±í•œ ê°€ì§œ ìƒ˜í”Œì„ **ì§„ì§œë¼ê³  íŒë³„**í•˜ë„ë¡ Discriminatorë¥¼ ì†ì´ê¸°.\n",
    "- ìµœì¢…ì ìœ¼ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì€ **min-max ê²Œì„**:\n",
    "$\n",
    "\\min_G \\max_D V(D, G) = \\mathbb{E}_{x \\sim p_{data}(x)}[\\log D(x)] + \\mathbb{E}_{z \\sim p_z(z)}[\\log (1 - D(G(z)))]\n",
    "$\n",
    "\n",
    "### ğŸš€ ì¥ì \n",
    "- ë§¤ìš° ì‚¬ì‹¤ì ì¸ ë°ì´í„°(ì´ë¯¸ì§€, ìŒì„± ë“±) ìƒì„± ê°€ëŠ¥.\n",
    "- ë°ì´í„° ì¦ê°•, ìŠ¤íƒ€ì¼ ë³€í™˜, ì´ë¯¸ì§€ ë³µì› ë“± ë‹¤ì–‘í•œ ìƒì„±ì  ì‘ìš© ê°€ëŠ¥.\n",
    "\n",
    "### âš ï¸ ë‹¨ì \n",
    "- **í›ˆë ¨ ë¶ˆì•ˆì •**: ê· í˜• ì¡íˆì§€ ì•Šìœ¼ë©´ Generatorë‚˜ Discriminator ì¤‘ í•˜ë‚˜ê°€ ì••ë„.\n",
    "- **Mode collapse**: Generatorê°€ ì¼ë¶€ íŒ¨í„´ë§Œ ìƒì„±í•˜ê³  ë‹¤ì–‘ì„±ì´ ë¶€ì¡±í•´ì§€ëŠ” í˜„ìƒ.\n",
    "- Hyperparameter íŠœë‹ì´ ì–´ë µê³  ë¯¼ê°.\n",
    "\n",
    "### âœ… í•œ ì¤„ ìš”ì•½\n",
    "> **\"GANì€ Generatorì™€ Discriminatorê°€ ê²½ìŸí•˜ë©°, ì§„ì§œ ê°™ì€ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ëª¨ë¸ì´ë‹¤.\"**\n",
    "\n",
    "### ğŸŸ¢ ìš”ì•½ í‘œ\n",
    "| í•­ëª©             | ì„¤ëª…                                       |\n",
    "|----------------|----------------------------------------|\n",
    "| ëª©ì             | ìƒˆë¡œìš´ ë°ì´í„°(ì´ë¯¸ì§€ ë“±) ìƒì„±              |\n",
    "| êµ¬ì„± ìš”ì†Œ      | Generator, Discriminator              |\n",
    "| í•™ìŠµ ë°©ì‹      | ì ëŒ€ì  í•™ìŠµ (Adversarial training)      |\n",
    "| ì¥ì            | ë§¤ìš° ì‚¬ì‹¤ì ì¸ ìƒ˜í”Œ ìƒì„± ê°€ëŠ¥            |\n",
    "| ë‹¨ì            | í•™ìŠµ ë¶ˆì•ˆì •, Mode collapse ë¬¸ì œ        |\n",
    "\n",
    "### ğŸ’¬ í™•ì¥ ë²„ì „ (ì˜ˆì‹œ)\n",
    "- **DCGAN**: CNN ê¸°ë°˜ GAN (ì´ë¯¸ì§€ ìƒì„± íŠ¹í™”).\n",
    "- **WGAN**: Wasserstein lossë¥¼ ì‚¬ìš©í•´ ì•ˆì •ì„± ê°œì„ .\n",
    "- **CycleGAN**: ì´ë¯¸ì§€ ê°„ ìŠ¤íƒ€ì¼ ë³€í™˜ (ì˜ˆ: ê²¨ìš¸ â†” ì—¬ë¦„).\n",
    "- **StyleGAN**: ë§¤ìš° ê³ í•´ìƒë„ì˜ ì‚¬ì‹¤ì ì¸ ì´ë¯¸ì§€ ìƒì„±.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15b910-295b-4cb5-b0a6-7723458c8c85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
