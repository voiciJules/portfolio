{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64481884-2b99-4ac2-aada-4bcc9396f452",
   "metadata": {},
   "source": [
    "# Before class 03\n",
    "- prof explains about the presentation 03(Hyperparameters and performance).\n",
    "\n",
    "## Initialization Methods in Neural Networks\n",
    "신경망에서 가중치를 어떻게 초기화하느냐는 학습 성능에 큰 영향을 미칩니다. 대표적으로 아래 세 가지 방식이 있습니다:\n",
    "\n",
    "### 1. Random Initialization (무작위 초기화)\n",
    "- **정의**: 가중치를 작은 무작위 값으로 초기화합니다.  \n",
    "- **이유**: 모든 가중치를 0으로 초기화하면 뉴런이 동일하게 업데이트되어 학습이 제대로 되지 않음.\n",
    "- **장점**: 간단하고 범용적으로 사용됨  \n",
    "- **단점**: 분포가 잘못되면 학습 실패 가능\n",
    "\n",
    "#### 종류:\n",
    "- **Xavier Initialization**: `tanh` 활성화 함수에 적합\n",
    "- **He Initialization**: `ReLU` 계열에 적합\n",
    "\n",
    "### 2. Transfer Learning (전이 학습)\n",
    "- **정의**: 사전 학습된 모델(예: ImageNet, BERT 등)의 가중치를 가져와서 초기값으로 사용\n",
    "- **활용 예시**:\n",
    "  - 이미지: ResNet, VGG\n",
    "  - 자연어: BERT, GPT\n",
    "- **장점**: 빠른 학습, 적은 데이터로 좋은 성능\n",
    "- **단점**: 도메인이 너무 다르면 전이 효과 ↓\n",
    "\n",
    "### 3. From Scratch (처음부터 학습)\n",
    "- **정의**: 가중치를 무작위로 초기화하고 처음부터 전체 학습을 수행\n",
    "- **활용**: 새로운 문제에 대해 처음 설계할 때 사용\n",
    "- **장점**: 도메인 특화된 모델 설계 가능  \n",
    "- **단점**: 많은 데이터와 연산 리소스 필요\n",
    "\n",
    "## ✅ 요약표\n",
    "\n",
    "| 초기화 방식        | 설명                                  | 장점                          | 단점                           |\n",
    "|-------------------|-----------------------------------------|-------------------------------|--------------------------------|\n",
    "| Random Init       | 무작위 값으로 가중치 초기화            | 간단, 범용 사용               | 수렴이 느리거나 불안정할 수 있음 |\n",
    "| Transfer Learning | 사전학습된 모델 가중치로 시작          | 빠른 학습, 적은 데이터로 가능 | 도메인이 다르면 효과 떨어질 수 있음 |\n",
    "| From Scratch      | 처음부터 가중치를 직접 학습            | 완전한 도메인 맞춤 가능       | 많은 데이터와 자원 필요        |\n",
    "\n",
    "---\n",
    "\n",
    "## Batch Normalization vs Layer Normalization\n",
    "\n",
    "### Batch Normalization\n",
    "- **배치 단위**로 정규화\n",
    "- 입력의 평균과 분산을 각 미니 배치에서 계산\n",
    "\n",
    "#### 수식\n",
    "$$\n",
    "\\hat{x}^{(k)} = \\frac{x^{(k)} - \\mu_B^{(k)}}{\\sqrt{(\\sigma_B^{(k)})^2 + \\epsilon}}\n",
    "$$\n",
    "\n",
    "#### 특징\n",
    "- 내부 공변량 변화 감소 (Internal Covariate Shift)\n",
    "- 큰 배치에서 효과적\n",
    "- CNN, DNN에 자주 사용\n",
    "- Dropout 필요성 감소\n",
    "\n",
    "### Layer Normalization\n",
    "- **샘플 단위**로 정규화\n",
    "- 각 입력 벡터의 평균과 분산을 사용\n",
    "\n",
    "#### 수식\n",
    "$$\n",
    "\\hat{x}_i = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}\n",
    "$$\n",
    "\n",
    "#### 특징\n",
    "- 배치 크기와 무관\n",
    "- RNN, Transformer에 적합\n",
    "- 학습 ↔ 추론 시기 차이 없음\n",
    "\n",
    "### 요약 비교\n",
    "\n",
    "| 항목                  | Batch Normalization                  | Layer Normalization                    |\n",
    "|----------------------|--------------------------------------|----------------------------------------|\n",
    "| 정규화 대상          | 같은 feature를 가진 배치 전체       | 하나의 샘플 내의 모든 feature          |\n",
    "| 계산 시점            | 배치 단위 평균과 분산 사용          | 각 샘플 기준 평균과 분산 사용         |\n",
    "| 배치 크기 의존성     | 있음                                 | 없음                                   |\n",
    "| 주 사용 분야         | CNN, DNN                             | RNN, Transformer 등 순차 모델         |\n",
    "| 훈련 ↔ 추론 차이     | 있음 (moving 평균 사용)             | 없음                                   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a19e12-7cfd-498b-bbbb-16bccf15c793",
   "metadata": {},
   "source": [
    "# Lecture 03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589eab91-3ecb-4a4b-95a6-35618dd0e5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ef6506-29b1-4cf9-8ffa-f66be30fe06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b496b5cd-fa78-4ba4-9c3b-98cae9ba209a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0860bc5-d818-4123-86a8-65f4a278c0d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b54d7-2362-4cc1-9bd5-51208007fa59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b87c8-aaeb-40e3-9eb3-0f04fba0d999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9203a9-23d6-480e-9587-e50e1744522e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
