{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQkpFI2UQ1nQ"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cNOqE4rcLyy-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain\n",
        "!pip install langchain-openai\n",
        "!pip install -U langchain-community\n",
        "!pip install unstructured\n",
        "!pip install openai\n",
        "!pip install chromadb\n",
        "!pip install Cython\n",
        "!pip install tiktoken\n",
        "!pip install unstructured[all]\n",
        "!pip install \"unstructured[pdf]\"\n",
        "!pip install pdfminer.six\n",
        "!pip install pi_heif\n",
        "!pip install unstructured-inference\n",
        "!pip install --upgrade nltk\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# poppler is a prerequisite for the pdf2image library to handle PDF conversions, and it needs to be installed on your system.\n",
        "%%capture\n",
        "!apt-get install -y poppler-utils\n",
        "!apt-get install -y tesseract-ocr\n"
      ],
      "metadata": {
        "id": "M21mkQsIBcSI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zwqefnqQ5XT"
      },
      "source": [
        "### Load Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sZyuQZbmMHRF"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import OpenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 전체 요약\n",
        "| 모듈                        | 역할         | 설명                                      |\n",
        "| ------------------------- | ---------- | --------------------------------------- |\n",
        "| `UnstructuredPDFLoader`   | 문서 로더      | PDF 파일을 텍스트로 읽어들이는 클래스                  |\n",
        "| `OpenAIEmbeddings`        | 임베딩 생성     | 텍스트를 벡터로 변환해주는 OpenAI 임베딩 클래스           |\n",
        "| `VectorstoreIndexCreator` | 벡터 인덱스 생성기 | 문서를 벡터 DB에 넣고 검색할 수 있게 준비하는 툴           |\n",
        "| `FAISS`                   | 벡터 DB      | 벡터를 저장하고 빠르게 검색할 수 있는 벡터 데이터베이스         |\n",
        "| `OpenAI`                  | LLM 사용     | ChatCompletion 등 OpenAI 모델과 대화할 수 있는 래퍼 |\n",
        "  \n",
        "1. from langchain.document_loaders import UnstructuredPDFLoader\n",
        "문서 로딩 도구입니다.\n",
        "- UnstructuredPDFLoader는 PDF를 읽고 내부의 텍스트를 추출합니다.\n",
        "- LangChain의 document_loader는 다양한 포맷 (PDF, DOCX, HTML 등)을 다룰 수 있습니다.\n",
        "- Unstructured 시리즈는 layout-aware한 텍스트 추출을 시도합니다.\n",
        "\n",
        "2. from langchain.embeddings import OpenAIEmbeddings\n",
        "- LangChain에 내장된 OpenAI의 임베딩 생성기입니다.\n",
        "- 텍스트 → 벡터로 변환하여 검색이나 유사도 분석에 활용합니다.\n",
        "- text-embedding-ada-002 같은 OpenAI 모델을 기반으로 동작합니다.\n",
        "\n",
        "3. from langchain.indexes import VectorstoreIndexCreator\n",
        "- 문서를 불러오고 임베딩하고, 벡터 스토어에 저장하는 모든 과정을 묶은 유틸 클래스입니다.\n",
        "- 자동으로 FAISS + OpenAIEmbedding 등을 연결해서 인덱스를 만들어 줍니다.\n",
        "- index = VectorstoreIndexCreator().from_loaders([loader]) 형식으로 자주 사용됩니다.\n",
        "\n",
        "4. from langchain.vectorstores import FAISS\n",
        "- Facebook이 만든 FAISS 벡터 검색 라이브러리를 래핑한 LangChain 모듈입니다.\n",
        "- 고속 벡터 검색이 가능한 오픈소스 라이브러리입니다.\n",
        "- FAISS 외에도 Chroma, Weaviate, Pinecone 등 다양한 vector store가 존재합니다.\n",
        "\n",
        "5. from langchain_openai import OpenAI\n",
        "- LangChain의 최신 구조에 맞춘 OpenAI 래퍼입니다.\n",
        "- langchain_openai는 [LangChain 0.1 이상] 버전에서 공식 분리된 패키지입니다.\n",
        "- OpenAI()를 통해 GPT-4나 GPT-3.5 같은 모델을 호출할 수 있습니다.\n",
        "- 최신 버전에서는 langchain_openai.OpenAI 사용을 권장합니다. (langchain.llms.OpenAI는 deprecated)\n",
        "```\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.3)\n",
        "```\n",
        "\n",
        "### 전체 흐름 예시\n",
        "```\n",
        "from langchain.document_loaders import UnstructuredPDFLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain_openai import OpenAI, OpenAIEmbeddings\n",
        "\n",
        "# 1. PDF 문서 로드\n",
        "loader = UnstructuredPDFLoader(\"example.pdf\")\n",
        "\n",
        "# 2. 벡터 인덱스 생성 (문서 임베딩 + 저장)\n",
        "index = VectorstoreIndexCreator(\n",
        "    embedding=OpenAIEmbeddings(),\n",
        "    vectorstore_cls=FAISS\n",
        ").from_loaders([loader])\n",
        "\n",
        "# 3. 사용자 질문에 대한 검색 및 응답\n",
        "query = \"이 문서의 핵심 요약은?\"\n",
        "result = index.query(query, llm=OpenAI(model=\"gpt-3.5-turbo\"))\n",
        "print(result)\n",
        "```"
      ],
      "metadata": {
        "id": "vswBLr0mRO2v"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xTspt2HQ-IF"
      },
      "source": [
        "### OpenAI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rRLZqAttMPPT"
      },
      "outputs": [],
      "source": [
        "# Get your API keys from openai, you will need to create an account.\n",
        "# Here is the link to get the keys: https://platform.openai.com/account/billing/overview\n",
        "import os\n",
        "\n",
        "my_openai_key = 'k-proj-P0tZZww7t6kCCjQ-uKPKXJtCKs0FGTqwlVcCeggFBnKnI2is4-YeY-guf3GWM66XSaTKZdO1rOT3BlbkFJTRw8RzazOu41guTAy4PmzdhQghK2M9ahgzX5J36GiJw18HBm6OGP-1U5wumsux-fKeOUb6LSYA'\n",
        "os.environ['OPENAI_API_KEY'] = my_openai_key  # os.environ은 Python의 환경변수(Environment Variables) 설정 객체이다. 실제 프로젝트에서는 보통 .env 파일이나 환경 변수로만 관리한다.\n",
        "my_open_key = my_openai_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXTO--zGRJYP"
      },
      "source": [
        "### Connect Google Drive\n",
        "How to Connect Google Colab with Google Drive - Highly Recommended -\n",
        "\n",
        "https://www.marktechpost.com/2019/06/07/how-to-connect-google-colab-with-google-drive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UOdGcvYkuGN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b8f58a-976b-4904-ee75-2becc1003c3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "--------Data Path in Google Drive \n",
            "\n",
            "/content/drive/My Drive/GenAI_sample_data/\n",
            "--------------------------------\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "base_path = '/content/drive/My Drive/'\n",
        "data_path_googleDrive='GenAI_sample_data/'\n",
        "data_path =os.path.join(base_path, data_path_googleDrive)\n",
        "print(\"--------Data Path in Google Drive \\n\")\n",
        "print(data_path)\n",
        "print(\"--------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bN-sa7AeKc12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636c86c1-6167-4d00-e9a7-d926994a0366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# connect your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW-sc_UnKc9Z",
        "outputId": "4512aaf9-36ac-4314-c2e9-019dc63278df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_dl.pdf',\n",
              " 'sample_DS_07Nov2024.pdf',\n",
              " 'sample_DS.pdf',\n",
              " 'sample_ML.pdf',\n",
              " 'sample_statistical_ml.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "pdf_folder_path = f'{root_dir}/GenAI_sample_data/sample_pdf_data/'\n",
        "os.listdir(pdf_folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VsMsK16kKdDi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5852332-656d-4136-81d6-24667c5abcfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /sample_nltk_data/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import nltk\n",
        "import os\n",
        "\n",
        "# Step 1: Create the NLTK data directory if it doesn't exist\n",
        "nltk_data_path = \"/sample_nltk_data/nltk_data\"\n",
        "os.makedirs(nltk_data_path, exist_ok=True)\n",
        "\n",
        "# Step 2: Set the NLTK data path\n",
        "nltk.data.path.append(nltk_data_path)\n",
        "\n",
        "# Step 3: Download the 'punkt' tokenizer to the specified directory\n",
        "nltk.download('punkt', download_dir=nltk_data_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /root/nltk_data/tokenizers/punkt. # why?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyn-ZRrKID0g",
        "outputId": "2807fd08-c916-4e22-dd81-bcb08deaa494"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/root/nltk_data/tokenizers/punkt': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFZhxGOrRRK_"
      },
      "source": [
        "### Load Multiple PDF files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TF1vWIDGK3-J"
      },
      "outputs": [],
      "source": [
        "# location of the pdf file/files.\n",
        "loaders = [UnstructuredPDFLoader(os.path.join(pdf_folder_path, fn)) for fn in os.listdir(pdf_folder_path)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI_beYYnK4By",
        "outputId": "60fd1035-26cf-482c-f6e4-161987ee16a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<langchain_community.document_loaders.pdf.UnstructuredPDFLoader at 0x794ed917aa90>,\n",
              " <langchain_community.document_loaders.pdf.UnstructuredPDFLoader at 0x794eda4261d0>,\n",
              " <langchain_community.document_loaders.pdf.UnstructuredPDFLoader at 0x794f18790950>,\n",
              " <langchain_community.document_loaders.pdf.UnstructuredPDFLoader at 0x794f186c0ed0>,\n",
              " <langchain_community.document_loaders.pdf.UnstructuredPDFLoader at 0x794eeb320790>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFehORDuRYFN"
      },
      "source": [
        "### Vector Store\n",
        "Chroma as vectorstore to index and search embeddings\n",
        "\n",
        "\n",
        "There are three main steps going on after the documents are loaded:\n",
        "\n",
        "- Splitting documents into chunks\n",
        "\n",
        "- Creating embeddings for each document\n",
        "\n",
        "- Storing documents and embeddings in a vectorstore\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ho9v_0qXK4E8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed94464-1eb4-4c00-b69f-265be50005d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain/indexes/vectorstore.py:171: UserWarning: Using InMemoryVectorStore as the default vectorstore.This memory store won't persist data. You should explicitlyspecify a vectorstore when using VectorstoreIndexCreator\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Initialize your embedding model\n",
        "embeddings = OpenAIEmbeddings()  # Or another embedding class you're using\n",
        "\n",
        "# Now pass the embedding to the VectorstoreIndexCreator\n",
        "index = VectorstoreIndexCreator(embedding=embeddings).from_loaders(loaders)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the LLM\n",
        "llm_for_question = OpenAI(temperature=0.1)  # Adjust the temperature as needed\n",
        "\n",
        "# Query the index with the LLM\n",
        "response = index.query('What was the main topic of the address?', llm=llm_for_question)\n",
        "\n",
        "# Print the response\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yiaIZH0NULS",
        "outputId": "65f508b4-48cc-407b-fe4d-04189bfea4a3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The main topic of the address is the impact of deep learning and BERT on the field of natural language processing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = index.query('who is mehdi?', llm=llm_for_question)\n",
        "\n",
        "# Print the response\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-jdpFoeK8r3",
        "outputId": "e7d763b1-9bb2-4c9a-a07e-91a15d081161"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mehdi is an instructor at the school who supervised the collection of this text using ChatGPT. You can contact Mehdi at zadeh1980mehdi@gmail.com.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "YihqyjcSK4Ic",
        "outputId": "070d4260-15c7-4874-e904-e01b3047959d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The text discusses the concept of deep learning and its impact on various industries, with a focus on BERT, a pre-trained transformer model designed for natural language processing. It explains the key features of BERT, such as its bidirectional approach and ability to understand contextual relationships between words, and highlights its potential for advancing AI applications.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "index.query('What was the summary of the address?', llm=llm_for_question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "znd10P9tQSMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078b9c82-ac86-44f5-83be-48a25a119c58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'what is Reinforcement Learning (RL)? ',\n",
              " 'answer': ' Reinforcement Learning (RL) is a subset of machine learning that involves learning through trial and error to optimize outcomes. It is used in various applications, such as image and speech recognition, recommendation systems, and predictive analytics. \\n',\n",
              " 'sources': '/content/gdrive/My Drive/GenAI_sample_data/sample_pdf_data/sample_ML.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "index.query_with_sources('what is Reinforcement Learning (RL)? ', llm=llm_for_question)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.query_with_sources('who is Mehdi ? ', llm=llm_for_question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NBPmStSOwCj",
        "outputId": "cb8de4fc-a45b-4b55-ec53-6a2fb2c2f1d3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'who is Mehdi ? ',\n",
              " 'answer': ' Mehdi is an instructor at the school.\\n',\n",
              " 'sources': '/content/gdrive/My Drive/GenAI_sample_data/sample_pdf_data/sample_DS_07Nov2024.pdf, /content/gdrive/My Drive/GenAI_sample_data/sample_pdf_data/sample_ML.pdf, /content/gdrive/My Drive/GenAI_sample_data/sample_pdf_data/sample_dl.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1nLYj55NzhJI"
      },
      "outputs": [],
      "source": [
        "# Initialize your embedding model with additional parameters\n",
        "model_kwargs = {\n",
        "    \"temperature\": 0.7                        # Set temperature for randomness in generation (0 to 1)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize your embedding model with additional parameters if needed\n",
        "embeddings_2 = OpenAIEmbeddings(\n",
        "    api_key=my_open_key                # Your OpenAI API key\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "4DygrkCSRoNu"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now pass the embedding to the VectorstoreIndexCreator\n",
        "index_2 = VectorstoreIndexCreator(embedding=embeddings_2).from_loaders(loaders)"
      ],
      "metadata": {
        "id": "uWS0nliTSVhT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5e1b8f-0703-4613-9645-344ad3590dd7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain/indexes/vectorstore.py:171: UserWarning: Using InMemoryVectorStore as the default vectorstore.This memory store won't persist data. You should explicitlyspecify a vectorstore when using VectorstoreIndexCreator\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the LLM\n",
        "llm_for_question_2 = OpenAI(temperature=0.9)  # Adjust the temperature as needed\n",
        "\n",
        "# Query the index with the LLM\n",
        "response = index.query('What was the main topic of the address?', llm=llm_for_question_2)\n",
        "\n",
        "# Print the response\n",
        "print(response)\n",
        "\n",
        "\n",
        "index.query_with_sources('who is Mehdi and what is his email? ', llm=llm_for_question_2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ewxrqELR93p",
        "outputId": "05b6b1a9-f761-49fe-dbd6-10ab3c6dbbf4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The main topic of the address was the role of deep learning and the transformer model BERT in revolutionizing natural language processing and its impact on various industries. \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': 'who is Mehdi and what is his email? ',\n",
              " 'answer': ' Mehdi is an instructor at the school.\\n',\n",
              " 'sources': '/content/gdrive/My Drive/GenAI_sample_data/sample_pdf_data/sample_DS_07Nov2024.pdf'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}